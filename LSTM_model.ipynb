{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from extraction.extract import *\n",
    "import math\n",
    "import numpy\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from datetime import datetime\n",
    "from scipy.stats import norm\n",
    "sys.path.append(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An LSTM model that trains on a time period of data in order to make a prediction at a predetermined time interval in the future is coded. Because LSTMs are designed to have a loockback interval where they look into the past to make a prediction in the future, a lot of data preparation must be done to be able to feed it to the model, as will be explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used for the LSTM model was generated with the external \"GenerateNNdata\". In order to make it compatible with the LSTM workframe the dataset had to be modified such that a certain number of past timesteps are used in order to predict a certain time in the future. The structure of the final version of the dataset is given by the \"series_to_supervised\" function, which takes care of only including data corresponding to the aforementioned timesteps. Moreover, the unnecessary columns ('departuresArrivalDelay' and 'arrivalsDepartureDelay') are dropped and the remaining ones are reordered such that the target features ('departuresDepartureDelay' and 'arrivalsArrivalDelay') are placed at the end. The data is also scaled and then further processed in order to drop the columns corresponding to future steps which we do not want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating NN data for EGLL with a timeslot length of 15 minutes\n",
      "Generating NN data for EGLL with a timeslot length of 15 minutes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-12)</th>\n",
       "      <th>var2(t-12)</th>\n",
       "      <th>var3(t-12)</th>\n",
       "      <th>var4(t-12)</th>\n",
       "      <th>var5(t-12)</th>\n",
       "      <th>var6(t-12)</th>\n",
       "      <th>var7(t-12)</th>\n",
       "      <th>var8(t-12)</th>\n",
       "      <th>var9(t-12)</th>\n",
       "      <th>var10(t-12)</th>\n",
       "      <th>...</th>\n",
       "      <th>var11(t)</th>\n",
       "      <th>var12(t)</th>\n",
       "      <th>var13(t)</th>\n",
       "      <th>var14(t)</th>\n",
       "      <th>var15(t)</th>\n",
       "      <th>var16(t)</th>\n",
       "      <th>var17(t)</th>\n",
       "      <th>var18(t)</th>\n",
       "      <th>var19(t+11)</th>\n",
       "      <th>var20(t+11)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.498141</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.480793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660256</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.322181</td>\n",
       "      <td>0.185567</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.559829</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064139</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.308550</td>\n",
       "      <td>0.628866</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.505576</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.105630</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.205535</td>\n",
       "      <td>0.335395</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.325534</td>\n",
       "      <td>0.368333</td>\n",
       "      <td>0.270422</td>\n",
       "      <td>0.325932</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.541176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248084</td>\n",
       "      <td>0.275556</td>\n",
       "      <td>0.171692</td>\n",
       "      <td>0.320733</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.203442</td>\n",
       "      <td>0.361481</td>\n",
       "      <td>0.134862</td>\n",
       "      <td>0.283505</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.344086</td>\n",
       "      <td>0.228116</td>\n",
       "      <td>0.411852</td>\n",
       "      <td>0.323039</td>\n",
       "      <td>0.331483</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2857 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var1(t-12)  var2(t-12)  var3(t-12)  var4(t-12)  var5(t-12)  var6(t-12)  \\\n",
       "12      0.052632        0.00    0.000000    0.000000    0.240000    0.498141   \n",
       "13      0.052632        0.00    0.000000    0.000000    0.240000    0.480793   \n",
       "14      0.052632        0.00    0.000000    0.000000    0.240000    0.322181   \n",
       "15      0.052632        0.05    0.000000    0.064139    0.186667    0.308550   \n",
       "16      0.052632        0.00    0.000000    0.000000    0.240000    0.505576   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2864    0.789474        0.35    0.242424    0.105630    0.314286    0.205535   \n",
       "2865    0.684211        0.40    0.253968    0.325534    0.368333    0.270422   \n",
       "2866    0.473684        0.30    0.000000    0.248084    0.275556    0.171692   \n",
       "2867    0.315789        0.45    0.177778    0.203442    0.361481    0.134862   \n",
       "2868    0.684211        0.90    0.344086    0.228116    0.411852    0.323039   \n",
       "\n",
       "      var7(t-12)  var8(t-12)  var9(t-12)  var10(t-12)  ...  var11(t)  \\\n",
       "12      0.896907    0.428571    0.030303          0.0  ...       0.0   \n",
       "13      0.000000    0.428571    0.030303          0.0  ...       0.0   \n",
       "14      0.185567    0.428571    0.030303          0.0  ...       0.0   \n",
       "15      0.628866    0.464286    0.060606          0.0  ...       0.0   \n",
       "16      0.010309    0.428571    0.030303          0.0  ...       0.0   \n",
       "...          ...         ...         ...          ...  ...       ...   \n",
       "2864    0.335395    0.178571    0.666667          0.0  ...       0.0   \n",
       "2865    0.325932    0.285714    0.636364          0.0  ...       0.0   \n",
       "2866    0.320733    0.357143    0.454545          0.0  ...       0.0   \n",
       "2867    0.283505    0.571429    0.454545          0.0  ...       0.0   \n",
       "2868    0.331483    0.642857    0.939394          0.0  ...       0.0   \n",
       "\n",
       "      var12(t)  var13(t)  var14(t)  var15(t)  var16(t)  var17(t)  var18(t)  \\\n",
       "12         0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "13         0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "14         0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "15         0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "16         0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2864       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2865       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2866       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2867       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2868       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "\n",
       "      var19(t+11)  var20(t+11)  \n",
       "12       0.269231     0.211765  \n",
       "13       0.660256     0.800000  \n",
       "14       0.559829     0.211765  \n",
       "15       0.533333     0.211765  \n",
       "16       0.512821     0.211765  \n",
       "...           ...          ...  \n",
       "2864     0.269231     0.211765  \n",
       "2865     0.269231     0.541176  \n",
       "2866     0.269231     0.211765  \n",
       "2867     0.269231     0.211765  \n",
       "2868     0.269231     0.211765  \n",
       "\n",
       "[2857 rows x 260 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-12)</th>\n",
       "      <th>var2(t-12)</th>\n",
       "      <th>var3(t-12)</th>\n",
       "      <th>var4(t-12)</th>\n",
       "      <th>var5(t-12)</th>\n",
       "      <th>var6(t-12)</th>\n",
       "      <th>var7(t-12)</th>\n",
       "      <th>var8(t-12)</th>\n",
       "      <th>var9(t-12)</th>\n",
       "      <th>var10(t-12)</th>\n",
       "      <th>...</th>\n",
       "      <th>var11(t)</th>\n",
       "      <th>var12(t)</th>\n",
       "      <th>var13(t)</th>\n",
       "      <th>var14(t)</th>\n",
       "      <th>var15(t)</th>\n",
       "      <th>var16(t)</th>\n",
       "      <th>var17(t)</th>\n",
       "      <th>var18(t)</th>\n",
       "      <th>var19(t+11)</th>\n",
       "      <th>var20(t+11)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257732</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.550980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256555</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.161710</td>\n",
       "      <td>0.613402</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.633484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.105741</td>\n",
       "      <td>0.570447</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.477564</td>\n",
       "      <td>0.662353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.132342</td>\n",
       "      <td>0.470103</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.381410</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.085295</td>\n",
       "      <td>0.537801</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.677941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.105630</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.205535</td>\n",
       "      <td>0.335395</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.325534</td>\n",
       "      <td>0.368333</td>\n",
       "      <td>0.270422</td>\n",
       "      <td>0.325932</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.541176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248084</td>\n",
       "      <td>0.275556</td>\n",
       "      <td>0.171692</td>\n",
       "      <td>0.320733</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.203442</td>\n",
       "      <td>0.361481</td>\n",
       "      <td>0.134862</td>\n",
       "      <td>0.283505</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.344086</td>\n",
       "      <td>0.228116</td>\n",
       "      <td>0.411852</td>\n",
       "      <td>0.323039</td>\n",
       "      <td>0.331483</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1967 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var1(t-12)  var2(t-12)  var3(t-12)  var4(t-12)  var5(t-12)  var6(t-12)  \\\n",
       "35      0.000000        0.00    0.000000    0.000000    0.240000    0.000000   \n",
       "36      0.105263        0.05    0.000000    0.256555    0.746667    0.161710   \n",
       "37      0.157895        0.00    0.000000    0.000000    0.240000    0.105741   \n",
       "38      0.263158        0.00    0.000000    0.000000    0.240000    0.132342   \n",
       "39      0.315789        0.00    0.000000    0.000000    0.240000    0.085295   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2864    0.789474        0.35    0.242424    0.105630    0.314286    0.205535   \n",
       "2865    0.684211        0.40    0.253968    0.325534    0.368333    0.270422   \n",
       "2866    0.473684        0.30    0.000000    0.248084    0.275556    0.171692   \n",
       "2867    0.315789        0.45    0.177778    0.203442    0.361481    0.134862   \n",
       "2868    0.684211        0.90    0.344086    0.228116    0.411852    0.323039   \n",
       "\n",
       "      var7(t-12)  var8(t-12)  var9(t-12)  var10(t-12)  ...  var11(t)  \\\n",
       "35      0.257732    0.464286    0.000000          0.0  ...       0.0   \n",
       "36      0.613402    0.428571    0.090909          0.0  ...       0.0   \n",
       "37      0.570447    0.357143    0.090909          0.0  ...       0.0   \n",
       "38      0.470103    0.285714    0.151515          0.0  ...       0.0   \n",
       "39      0.537801    0.250000    0.181818          0.0  ...       0.0   \n",
       "...          ...         ...         ...          ...  ...       ...   \n",
       "2864    0.335395    0.178571    0.666667          0.0  ...       0.0   \n",
       "2865    0.325932    0.285714    0.636364          0.0  ...       0.0   \n",
       "2866    0.320733    0.357143    0.454545          0.0  ...       0.0   \n",
       "2867    0.283505    0.571429    0.454545          0.0  ...       0.0   \n",
       "2868    0.331483    0.642857    0.939394          0.0  ...       0.0   \n",
       "\n",
       "      var12(t)  var13(t)  var14(t)  var15(t)  var16(t)  var17(t)  var18(t)  \\\n",
       "35         0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n",
       "36         0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n",
       "37         0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n",
       "38         0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n",
       "39         0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2864       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2865       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2866       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2867       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2868       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "\n",
       "      var19(t+11)  var20(t+11)  \n",
       "35       0.562500     0.550980  \n",
       "36       0.615385     0.633484  \n",
       "37       0.477564     0.662353  \n",
       "38       0.381410     0.680000  \n",
       "39       0.545455     0.677941  \n",
       "...           ...          ...  \n",
       "2864     0.269231     0.211765  \n",
       "2865     0.269231     0.541176  \n",
       "2866     0.269231     0.211765  \n",
       "2867     0.269231     0.211765  \n",
       "2868     0.269231     0.211765  \n",
       "\n",
       "[1967 rows x 260 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "\n",
    "# Generate single airport data and move target labels to the last 2 columns \n",
    "dataset = generateNNdata(\"EGLL\", timeslotLength=15, catagoricalFlightDuration=False, start=datetime(2018, 3, 1), end=datetime(2018, 3, 31), forceRegenerateData=True)\n",
    "dataset = dataset.set_index(\"timeslot\")\n",
    "dataset.drop(columns=['departuresArrivalDelay','arrivalsDepartureDelay'])\n",
    "label1 = dataset.pop('departuresDepartureDelay')\n",
    "dataset.insert(len(dataset.columns), 'departuresDepartureDelay', label1)\n",
    "label2 = dataset.pop('arrivalsArrivalDelay')\n",
    "dataset.insert(len(dataset.columns), 'arrivalsArrivalDelay', label2)\n",
    "# display(dataset)\n",
    "test_dataset = generateNNdata(\"EGLL\", timeslotLength=15, catagoricalFlightDuration=False, start=datetime(2018, 6, 1), end=datetime(2018, 6, 30), forceRegenerateData=True)\n",
    "test_dataset = test_dataset.set_index(\"timeslot\")\n",
    "test_dataset.drop(columns=['departuresArrivalDelay','arrivalsDepartureDelay'])\n",
    "label1 = test_dataset.pop('departuresDepartureDelay')\n",
    "test_dataset.insert(len(test_dataset.columns), 'departuresDepartureDelay', label1)\n",
    "label2 = test_dataset.pop('arrivalsArrivalDelay')\n",
    "test_dataset.insert(len(test_dataset.columns), 'arrivalsArrivalDelay', label2)\n",
    "\n",
    "\n",
    "# Normalize values\n",
    "values = dataset.values\n",
    "test_values = test_dataset.values\n",
    "\n",
    "\n",
    "# Ensure all data is float\n",
    "values = values.astype('float32')\n",
    "test_values = test_values.astype('float32')\n",
    "\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "test_scaled = scaler.fit_transform(test_values)\n",
    "# display(scaled)\n",
    "\n",
    "\n",
    "# Frame as supervised learning\n",
    "number_of_past_steps = 12\n",
    "number_of_future_steps = 12\n",
    "# number_of_future_steps2 = 6\n",
    "number_of_outputs = 2\n",
    "reframed = series_to_supervised(scaled, n_in=number_of_past_steps, n_out=number_of_future_steps)\n",
    "test_reframed = series_to_supervised(test_scaled, n_in=number_of_past_steps, n_out=number_of_future_steps)\n",
    "\n",
    "\n",
    "# Create a list of column names to drop\n",
    "column_drop_lst = []\n",
    "for timestep in range(number_of_future_steps):\n",
    "    for variable in range(1, len(dataset.columns) + 1):\n",
    "        if timestep == 0:\n",
    "            if variable > len(dataset.columns) - number_of_outputs:\n",
    "                column_drop_lst.append(f\"var{variable}(t)\")\n",
    "        elif timestep == number_of_future_steps-1 and variable > len(dataset.columns) - number_of_outputs:\n",
    "            pass\n",
    "        else:\n",
    "            column_drop_lst.append(f\"var{variable}(t+{timestep})\")\n",
    "\n",
    "# column_drop_lst.remove(f'var19(t+{number_of_future_steps2-1})')\n",
    "# column_drop_lst.remove(f'var20(t+{number_of_future_steps2-1})')\n",
    "\n",
    "\n",
    "# Drop columns we don't want to predict\n",
    "reframed.drop(columns=reframed[column_drop_lst], inplace=True)\n",
    "test_reframed.drop(columns=test_reframed[column_drop_lst], inplace=True)\n",
    "display(reframed)\n",
    "# display(test_reframed)\n",
    "\n",
    "\n",
    "# Remove rows that contain variables of night\n",
    "for timestep in range(1, number_of_past_steps):\n",
    "    reframed = reframed.query(f'`var1(t-{timestep})` != 0 | `var2(t-{timestep})` != 0')\n",
    "\n",
    "for timestep in range(1, number_of_past_steps):\n",
    "    no_night_reframed = test_reframed.query(f'`var1(t-{timestep})` != 0 | `var2(t-{timestep})` != 0')\n",
    "\n",
    "display(reframed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is used to explore the distribution of the output variables by plotting their normal distributions and also their correspinding histograms (for visualisation purposes). This will give us an indication for the accuracy of our model and whether the obtained performance metrics make sense in relation to the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deprartures Departure Delay mean: 2.78\n",
      "Arrivals Arrival Delay mean: 13.86\n",
      "Deprartures Departure Delay standard deviation: 7.02\n",
      "Arrivals Arrival Delay standard deviation: 11.71\n"
     ]
    }
   ],
   "source": [
    "depdel = dataset[\"departuresDepartureDelay\"].to_numpy()\n",
    "arrdel = dataset[\"arrivalsArrivalDelay\"].to_numpy()\n",
    "\n",
    "mean_depdel= numpy.mean(depdel)\n",
    "std_depdel = numpy.std(depdel)\n",
    "mean_arrdel = numpy.mean(arrdel)\n",
    "std_arrdel = numpy.std(arrdel)\n",
    "\n",
    "x_depdel = numpy.linspace(mean_depdel - 3*std_depdel, mean_depdel + 3*std_depdel, 100)\n",
    "x_arrdel = numpy.linspace(mean_arrdel - 3*std_arrdel, mean_arrdel + 3*std_arrdel, 100)\n",
    "\n",
    "normal_depdel = norm.pdf(x_depdel, mean_depdel, std_depdel)\n",
    "normal_arrdel = norm.pdf(x_arrdel, mean_arrdel, std_arrdel)\n",
    "\n",
    "plt.figure(1)\n",
    "bin_num = 25\n",
    "plt.title('Delays Distribution')\n",
    "plt.hist(depdel, bins=bin_num, label='Departures Departure Delay')\n",
    "plt.hist(arrdel, bins=bin_num, label='Arrivals Arrival Delay')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title(\"Delays Normal Distribution\")\n",
    "plt.plot(x_depdel, normal_depdel, label='Departures Departure Delay')\n",
    "plt.plot(x_arrdel, normal_arrdel, label='Arrivals Arrival Delay')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Deprartures Departure Delay mean:\", round(mean_depdel, 2))\n",
    "print(\"Arrivals Arrival Delay mean:\", round(mean_arrdel, 2))\n",
    "print(\"Deprartures Departure Delay standard deviation:\", round(std_depdel, 2))\n",
    "print(\"Arrivals Arrival Delay standard deviation:\", round(std_arrdel, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE AND FIT INITIAL MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can be seen below is the splitting of the data into the training and the test sets. Out of the one month worth of data, 600 hours are used for training and the rest are used for testing. After reshaping the sets into the desired form for the proper functioning of the LSTM, the data is fitted on a single-layer LSTM model. After iterating multiple times for different numbers of epochs, we decided that 50 epochs are enough, since the errors did not change significantly after this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1, 200)            367200    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 200)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1, 400)            961600    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 400)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1, 50)             20050     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1, 800)            2723200   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 50)             40050     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 300)               421200    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                7525      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 4,541,107\n",
      "Trainable params: 4,541,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test MAE1: 1.003\n",
      "Test MAE2: 1.344\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "values = reframed.values\n",
    "test_values = test_reframed.values\n",
    "no_night_values = no_night_reframed.values\n",
    "val_ratio = 0.3\n",
    "train_index = int(val_ratio * len(reframed))\n",
    "\n",
    "\n",
    "# Split into train and test sets\n",
    "train = values[:(train_index), :]\n",
    "val = values[train_index:, :]\n",
    "test = test_values\n",
    "no_night = no_night_values\n",
    "\n",
    "# Split into input and outputs\n",
    "train_X, train_y = train[:, :-2], train[:, -2:]\n",
    "val_X, val_y = val[:, :-2], val[:, -2:]\n",
    "test_X, test_y = test[:, :-2], test[:, -2:]\n",
    "no_night_X, no_night_y = no_night[:, :-2], no_night[:, -2:]\n",
    "\n",
    "\n",
    "# Reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], -1, train_X.shape[1]))\n",
    "val_X = val_X.reshape((val_X.shape[0], -1, val_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], -1, test_X.shape[1]))\n",
    "no_night_X = no_night_X.reshape((no_night_X.shape[0], -1, no_night_X.shape[1]))\n",
    "\n",
    "# Design LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(LSTM(400, return_sequences=True))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(50))\n",
    "model.add(LSTM(800, return_sequences=True))\n",
    "model.add(Dense(50))\n",
    "model.add(LSTM(300))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(25))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(2))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Fit data\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data = (test_X, test_y), verbose=0, shuffle=False)\n",
    "\n",
    "\n",
    "# Accuracies of seperate month of data\n",
    "# all_times_accuracy = model.evaluate(test_X, test_y)\n",
    "# no_night_accuracy = model.evaluate(no_night_X, no_night_y)\n",
    "# print(\"Accuracy of all data of June:\", round(all_times_accuracy,5))\n",
    "# print(\"Accuracy of no night data of June:\", round(no_night_accuracy, 5))\n",
    "\n",
    "\n",
    "# Generate predictions\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "\n",
    "# Split and reshape the two desired outputs in separate arrays to prepare for inverse scaling\n",
    "yhat1 = yhat[:, 0]\n",
    "yhat2 = yhat[:, 1]\n",
    "yhat1 = yhat1.reshape(len(yhat), 1)\n",
    "yhat2 = yhat2.reshape(len(yhat), 1)\n",
    "\n",
    "\n",
    "# Also split the real values of the labels and reshape for inverse scaling\n",
    "test_y_1 = test_y[:, 0]\n",
    "test_y_2 = test_y[:, 1]\n",
    "test_y_1 = test_y_1.reshape(len(test_y), 1)\n",
    "test_y_2 = test_y_2.reshape(len(test_y), 1)\n",
    "\n",
    "\n",
    "# Inverse transform the predictions\n",
    "inv_yhat_1 = concatenate((yhat1, yhat2, test_X[:, 0:18]), axis=1)\n",
    "inv_yhat_1 = scaler.inverse_transform(inv_yhat_1)\n",
    "inv_yhat_1 = inv_yhat_1[:, :2]\n",
    "\n",
    "\n",
    "# Inverse transform the real values of the labels\n",
    "inv_y_1 = concatenate((test_y_1, test_y_2, test_X[:, 0:18]), axis=1)\n",
    "inv_y_1 = scaler.inverse_transform(inv_y_1)\n",
    "inv_y_1 = inv_y_1[:, :2]\n",
    "\n",
    "\n",
    "# calculate MAE between predicted and actual labels\n",
    "mae1 = mean_absolute_error(inv_y_1[:, 0], inv_yhat_1[:, 0])\n",
    "mae2 = mean_absolute_error(inv_y_1[:, 1], inv_yhat_1[:, 1])\n",
    "\n",
    "\n",
    "print('Test MAE1: %.3f' % mae1)\n",
    "print('Test MAE2: %.3f' % mae2)\n",
    "\n",
    "\n",
    "# Plot loss\n",
    "plt.title(\"Loss vs Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "pyplot.plot(history.history['loss'], label='Train Loss')\n",
    "pyplot.plot(history.history['val_loss'], label='Validation Loss')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two cells are used for tuning the number of neurons of the LSTM model and the look-back parameter (that is, how much back in time we go for training the LSTM), respectively. The mean absolute errors are plotted against both of these parameters and the minimums are found for each case. In order to keep the running time at an acceptable level, the two tunings are performed separately, in order to offer a general view on the best values of these parameters. It is also observed that the minimum values of the MAE's only vary by a very tiny amount, regardless of the parameters' values. The obtained results are also inverse scaled back to the initial scale for visualising them and for having the MAE's in the desired scale as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17828/3417315557.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# fit network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m72\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#validation_data=(val_X, val_y),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m-> 3038\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    981\u001b[0m           \u001b[1;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m           \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 983\u001b[1;33m             return autograph.converted_call(\n\u001b[0m\u001b[0;32m    984\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Allowlisted %s: from cache'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    462\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m    844\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1284\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1285\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1286\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2847\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2848\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2849\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2851\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3630\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3631\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3632\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3634\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m         \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    789\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n\u001b[0;32m    790\u001b[0m     \u001b[1;31m# Run backwards pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    792\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[1;31m# Collect metrics to return\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m     \"\"\"\n\u001b[1;32m--> 520\u001b[1;33m     grads_and_vars = self._compute_gradients(\n\u001b[0m\u001b[0;32m    521\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0;32m    522\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/gradients\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m       \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     self._assert_valid_dtypes([\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    452\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1082\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1085\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_backward_function\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    843\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_backward_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m       \u001b[0mcall_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 845\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rewrite_forward_and_call_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    846\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_backward_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_rewrite_forward_and_call_backward\u001b[1;34m(self, op, *doutputs)\u001b[0m\n\u001b[0;32m    758\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_rewrite_forward_and_call_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mdoutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;34m\"\"\"Add outputs to the forward call and feed them to the grad function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m     \u001b[0mforward_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackwards_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbackwards_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mbackwards_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructured_outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mforward_backward\u001b[1;34m(self, num_doutputs)\u001b[0m\n\u001b[0;32m    691\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mforward_backward\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m     \u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_forward_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_construct_forward_backward\u001b[1;34m(self, num_doutputs)\u001b[0m\n\u001b[0;32m    734\u001b[0m       backwards_graph = func_graph_module.FuncGraph(\n\u001b[0;32m    735\u001b[0m           _backward_name(self._func_graph.name))\n\u001b[1;32m--> 736\u001b[1;33m       func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m    737\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbackwards_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m           \u001b[0mpython_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_backprop_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_backprop_function\u001b[1;34m(*grad_ys)\u001b[0m\n\u001b[0;32m    725\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_backprop_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         return gradients_util._GradientsHelper(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    728\u001b[0m             \u001b[0mtrainable_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    679\u001b[0m                 \u001b[1;31m# If grad_fn was found, do not use SymbolicGradient even for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0m\u001b[0;32m    682\u001b[0m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0;32m    683\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Exit early\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m   \u001b[1;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 682\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    683\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py\u001b[0m in \u001b[0;36m_StridedSliceGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    273\u001b[0m   \u001b[1;31m# We could choose any of {begin|end|strides}.dtype since they are required to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m   \u001b[1;31m# be the same.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m   \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m   \u001b[0mx_static\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[1;34m(input, name, out_type)\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m   \"\"\"\n\u001b[1;32m--> 651\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[1;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[0;32m    677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 679\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[1;34m(input, out_type, name)\u001b[0m\n\u001b[0;32m   9196\u001b[0m     \u001b[0mout_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9197\u001b[0m   \u001b[0mout_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"out_type\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9198\u001b[1;33m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[0;32m   9199\u001b[0m         \"Shape\", input=input, out_type=out_type, name=name)\n\u001b[0;32m   9200\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    746\u001b[0m       \u001b[1;31m# Add Op to graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[0;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    595\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mctxt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"AddValue\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAddValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m       \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mcapture\u001b[1;34m(self, tensor, name, shape)\u001b[0m\n\u001b[0;32m    647\u001b[0m               % (tensor, tensor.graph, self))\n\u001b[0;32m    648\u001b[0m         \u001b[0minner_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_capture_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_capture_helper\u001b[1;34m(self, tensor, name, shape)\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[0mcapture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_captures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcapture\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m       placeholder = _create_substitute_placeholder(\n\u001b[0m\u001b[0;32m    656\u001b[0m           tensor, name=name, dtype=tensor.dtype, shape=shape)\n\u001b[0;32m    657\u001b[0m       \u001b[1;31m# Record the composite device as an attribute to the placeholder.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_substitute_placeholder\u001b[1;34m(value, name, dtype, shape)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m     placeholder = graph_placeholder(\n\u001b[0m\u001b[0;32m   1152\u001b[0m         dtype=dtype or value.dtype, shape=shape, name=name)\n\u001b[0;32m   1153\u001b[0m   \u001b[0mhandle_data_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\graph_only_ops.py\u001b[0m in \u001b[0;36mgraph_placeholder\u001b[1;34m(dtype, shape, name)\u001b[0m\n\u001b[0;32m     36\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m   op = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m     39\u001b[0m       \u001b[1;34m\"Placeholder\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m       attrs=attrs, name=name)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    600\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         compute_device)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3559\u001b[0m     \u001b[1;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3560\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3561\u001b[1;33m       ret = Operation(\n\u001b[0m\u001b[0;32m   3562\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3563\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2039\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2041\u001b[1;33m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[0;32m   2042\u001b[0m                                 control_input_ops, op_def)\n\u001b[0;32m   2043\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1879\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1880\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1881\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mae1_lst = []\n",
    "mae2_lst = []\n",
    "neurons_lst = numpy.arange(2, 300, 1)\n",
    "\n",
    "for neurons in neurons_lst:\n",
    "\n",
    "\n",
    "    # Design the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(LSTM(2*neurons, return_sequences=True))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(50))\n",
    "    model.add(LSTM(4*neurons, return_sequences=True))\n",
    "    model.add(Dense(50))\n",
    "    model.add(LSTM(2*neurons))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(2))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    # model.summary()\n",
    "\n",
    "\n",
    "    # fit network\n",
    "    history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data = (val_X, val_y), verbose=0, shuffle=False) #validation_data=(val_X, val_y),\n",
    "\n",
    "\n",
    "    # Generate predictions\n",
    "\n",
    "    yhat = model.predict(val_X)\n",
    "    reshaped_val_X = val_X.reshape((val_X.shape[0], val_X.shape[2]))\n",
    "\n",
    "\n",
    "    # Split and reshape the two desired outputs in separate arrays to prepare for inverse scaling\n",
    "    yhat1 = yhat[:, 0]\n",
    "    yhat2 = yhat[:, 1]\n",
    "    yhat1 = yhat1.reshape(len(yhat), 1)\n",
    "    yhat2 = yhat2.reshape(len(yhat), 1)\n",
    "\n",
    "\n",
    "    # Also split the real values of the labels and reshape for inverse scaling\n",
    "    val_y_1 = val_y[:, 0]\n",
    "    val_y_2 = val_y[:, 1]\n",
    "    val_y_1 = val_y_1.reshape(len(val_y), 1)\n",
    "    val_y_2 = val_y_2.reshape(len(val_y), 1)\n",
    "\n",
    "\n",
    "    # Inverse transform the predictions\n",
    "    inv_yhat_1 = concatenate((yhat1, yhat2, reshaped_val_X[:, 0:18]), axis=1)\n",
    "    inv_yhat_1 = scaler.inverse_transform(inv_yhat_1)\n",
    "    inv_yhat_1 = inv_yhat_1[:, :2]\n",
    "\n",
    "\n",
    "    # Inverse transform the real values of the labels\n",
    "    inv_y_1 = concatenate((val_y_1, val_y_2, reshaped_val_X[:, 0:18]), axis=1)\n",
    "    inv_y_1 = scaler.inverse_transform(inv_y_1)\n",
    "    inv_y_1 = inv_y_1[:, :2]\n",
    "\n",
    "\n",
    "    # calculate MAE between predicted and actual labels\n",
    "\n",
    "    mae1 = mean_absolute_error(inv_y_1[:, 0], inv_yhat_1[:, 0])\n",
    "    mae1_lst.append(mae1)\n",
    "    mae2 = mean_absolute_error(inv_y_1[:, 1], inv_yhat_1[:, 1])\n",
    "    mae2_lst.append(mae2)\n",
    "\n",
    "\n",
    "# Plot MAE vs neurons\n",
    "plt.title(\"MAE vs number of neurons\")\n",
    "plt.plot(neurons_lst, mae1_lst, label = 'mae1')\n",
    "plt.plot(neurons_lst, mae2_lst, label = 'mae2')\n",
    "plt.xlabel(\"Neurons\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('minimum mae1 is {} for a number of {} neurons'.format(numpy.min(mae1_lst), neurons_lst[mae1_lst.index(numpy.min(mae1_lst))]))\n",
    "print('minimum mae2 is {} for a number of {} neurons'. format(numpy.min(mae2_lst), neurons_lst[mae2_lst.index(numpy.min(mae2_lst))]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae1_lst = []\n",
    "mae2_lst = []\n",
    "lookback_lst = numpy.arange(1, 100, 1) \n",
    "number_of_future_steps = 6\n",
    "\n",
    "\n",
    "\n",
    "for lookback in lookback_lst:\n",
    "\n",
    "    number_of_past_steps = lookback  \n",
    "    reframed = series_to_supervised(scaled, n_in=number_of_past_steps, n_out=number_of_future_steps)\n",
    "\n",
    "    # drop columns we don't want to predict\n",
    "    reframed.drop(columns=reframed.columns[[i for i in range(len(reframed.columns)-20, len(reframed.columns)-2)]], inplace=True)\n",
    "    values = reframed.values\n",
    "    values = values.astype('float32')\n",
    "\n",
    "\n",
    "    # normalize features\n",
    "    number_of_hours_to_train = 600\n",
    "    number_of_timeslots_in_one_hour = 4 # 4 for 15 minute intervals, 1 for 1 hour intervals\n",
    "    train_index = number_of_hours_to_train * number_of_timeslots_in_one_hour\n",
    "\n",
    "\n",
    "    # split into train and validation sets\n",
    "    train = values[:(train_index), :]\n",
    "    val = values[train_index:, :]\n",
    "\n",
    "\n",
    "    # split into input and outputs\n",
    "    train_X, train_y = train[:, :-2], train[:, -2:]\n",
    "    val_X, val_y = val[:, :-2], val[:, -2:]\n",
    "\n",
    "\n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], -1, train_X.shape[1]))\n",
    "    val_X = val_X.reshape((val_X.shape[0], -1, val_X.shape[1]))\n",
    "\n",
    "    # fit network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(LSTM(400, return_sequences=True))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(50))\n",
    "    model.add(LSTM(800, return_sequences=True))\n",
    "    model.add(Dense(50))\n",
    "    model.add(LSTM(300))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(2))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    # model.summary()\n",
    "    \n",
    "    history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data = (val_X, val_y), verbose=0, shuffle=False) #validation_data=(val_X, val_y),\n",
    "\n",
    "\n",
    "    # Generate predictions\n",
    "    yhat = model.predict(val_X)\n",
    "    reshaped_val_X = val_X.reshape((val_X.shape[0], val_X.shape[2]))\n",
    "\n",
    "\n",
    "    # Split and reshape the two desired outputs in separate arrays to prepare for inverse scaling\n",
    "    yhat1 = yhat[:, 0]\n",
    "    yhat2 = yhat[:, 1]\n",
    "    yhat1 = yhat1.reshape(len(yhat), 1)\n",
    "    yhat2 = yhat2.reshape(len(yhat), 1)\n",
    "\n",
    "\n",
    "    # Split real values of the labels and reshape for inverse scaling\n",
    "    val_y_1 = val_y[:, 0]\n",
    "    val_y_2 = val_y[:, 1]\n",
    "    val_y_1 = val_y_1.reshape(len(val_y), 1)\n",
    "    val_y_2 = val_y_2.reshape(len(val_y), 1)\n",
    "\n",
    "\n",
    "    # Inverse transform the predictions\n",
    "    inv_yhat_1 = concatenate((yhat1, yhat2, reshaped_val_X[:, 0:18]), axis=1)\n",
    "    inv_yhat_1 = scaler.inverse_transform(inv_yhat_1)\n",
    "    inv_yhat_1 = inv_yhat_1[:, :2]\n",
    "\n",
    "\n",
    "    # Inverse transform the real values of the labels\n",
    "    inv_y_1 = concatenate((val_y_1, val_y_2, reshaped_val_X[:, 0:18]), axis=1)\n",
    "    inv_y_1 = scaler.inverse_transform(inv_y_1)\n",
    "    inv_y_1 = inv_y_1[:, :2]\n",
    "\n",
    "\n",
    "    # Calculate MAE between predicted and actual labels\n",
    "    mae1 = mean_absolute_error(inv_y_1[:, 0], inv_yhat_1[:, 0])\n",
    "    mae1_lst.append(mae1)\n",
    "    mae2 = mean_absolute_error(inv_y_1[:, 1], inv_yhat_1[:, 1])\n",
    "    mae2_lst.append(mae2)\n",
    "\n",
    "\n",
    "# Plot MAE vs lookback\n",
    "plt.title(\"MAEs vs lookback\")\n",
    "plt.plot(lookback_lst, mae1_lst, label = 'mae1')\n",
    "plt.plot(lookback_lst, mae2_lst, label = 'mae2')\n",
    "plt.xlabel(\"Lookback\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('minimum mae1 is {} for a lookback of {}'.format(numpy.min(mae1_lst), lookback_lst[mae1_lst.index(numpy.min(mae1_lst))]))\n",
    "print('minimum mae2 is {} for a lookback of {}'. format(numpy.min(mae2_lst), lookback_lst[mae2_lst.index(numpy.min(mae2_lst))]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION OF FINAL MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the final model consisting of the optimal obtained parameters (which can be seen below) is fitted and run again in order to obtain what should be the most accurate results as far as the performed tuning allows us to obtain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPTIMAL PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 10\n",
    "number_of_past_steps = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize values\n",
    "values = dataset.values\n",
    "# display(values)\n",
    "\n",
    "\n",
    "# Ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# print(scaled)\n",
    "\n",
    "# Frame as supervised learning\n",
    "number_of_future_steps = 12\n",
    "number_of_outputs = 2\n",
    "reframed = series_to_supervised(scaled, n_in=number_of_past_steps, n_out=number_of_future_steps)\n",
    "\n",
    "\n",
    "# Create a list of column names to drop\n",
    "column_drop_lst = []\n",
    "\n",
    "for timestep in range(number_of_future_steps):\n",
    "    for variable in range(1, len(dataset.columns) + 1):\n",
    "        if timestep == 0:\n",
    "            if variable > len(dataset.columns) - number_of_outputs:\n",
    "                column_drop_lst.append(f\"var{variable}(t)\")\n",
    "        elif timestep == number_of_future_steps-1 and variable > len(dataset.columns) - number_of_outputs:\n",
    "            pass\n",
    "        else:\n",
    "            column_drop_lst.append(f\"var{variable}(t+{timestep})\")\n",
    "# print(column_drop_lst)\n",
    "\n",
    "\n",
    "# Drop columns we don't want to predict\n",
    "reframed.drop(columns=reframed[column_drop_lst], inplace=True)\n",
    "\n",
    "\n",
    "display(reframed)\n",
    "\n",
    "\n",
    "# Train index calculation\n",
    "values = reframed.values\n",
    "number_of_hours_to_train = 600\n",
    "number_of_timeslots_in_one_hour = 4 # 4 for 15 minute intervals, 1 for 1 hour intervals\n",
    "train_index = number_of_hours_to_train * number_of_timeslots_in_one_hour\n",
    "\n",
    "\n",
    "# Split into train and test sets\n",
    "train = values[:(train_index), :]\n",
    "test = values[train_index:, :]\n",
    "\n",
    "\n",
    "# Split into input and outputs\n",
    "train_X, train_y = train[:, :-2], train[:, -2:]\n",
    "test_X, test_y = test[:, :-2], test[:, -2:]\n",
    "\n",
    "\n",
    "# Reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], -1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], -1, test_X.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DEFINE AND FIT THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design final model\n",
    "model = Sequential()\n",
    "model.add(LSTM(neurons, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(2))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "\n",
    "# Fit data\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data = (test_X, test_y), verbose=0, shuffle=False) #validation_data=(val_X, val_y),\n",
    "\n",
    "\n",
    "# Plot loss\n",
    "plt.title(\"Train and Validation loss vs Epochs\")\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='validation')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EVALUATE FINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "\n",
    "# Split and reshape the two desired outputs in separate arrays to prepare for inverse scaling\n",
    "yhat1 = yhat[:, 0]\n",
    "yhat2 = yhat[:, 1]\n",
    "yhat1 = yhat1.reshape(len(yhat), 1)\n",
    "yhat2 = yhat2.reshape(len(yhat), 1)\n",
    "\n",
    "\n",
    "# Also split the real values of the labels and reshape for inverse scaling\n",
    "test_y_1 = test_y[:, 0]\n",
    "test_y_2 = test_y[:, 1]\n",
    "test_y_1 = test_y_1.reshape(len(test_y), 1)\n",
    "test_y_2 = test_y_2.reshape(len(test_y), 1)\n",
    "\n",
    "\n",
    "# Inverse transform the predictions\n",
    "inv_yhat_1 = concatenate((yhat1, yhat2, test_X[:, 0:18]), axis=1)\n",
    "inv_yhat_1 = scaler.inverse_transform(inv_yhat_1)\n",
    "inv_yhat_1 = inv_yhat_1[:, :2]\n",
    "\n",
    "\n",
    "# Inverse transform the real values of the labels\n",
    "inv_y_1 = concatenate((test_y_1, test_y_2, test_X[:, 0:18]), axis=1)\n",
    "inv_y_1 = scaler.inverse_transform(inv_y_1)\n",
    "inv_y_1 = inv_y_1[:, :2]\n",
    "\n",
    "\n",
    "# calculate MAE between predicted and actual labels\n",
    "mae1 = mean_absolute_error(inv_y_1[:, 0], inv_yhat_1[:, 0])\n",
    "mae2 = mean_absolute_error(inv_y_1[:, 1], inv_yhat_1[:, 1])\n",
    "\n",
    "\n",
    "print('Test MAE1: %.3f' % mae1)\n",
    "print('Test MAE2: %.3f' % mae2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NON SCALED LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an attempt to see how the model would wok if we don't scale the outputs. However it's a bit outdated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "\n",
    "dataset = generateNNdata(\"EHAM\", timeslotLength=15, catagoricalFlightDuration=False)\n",
    "dataset = dataset.set_index(\"timeslot\")\n",
    "dataset.drop(columns=['departuresArrivalDelay','arrivalsArrivalDelay'])\n",
    "label = dataset.pop('departuresDepartureDelay')\n",
    "dataset.insert(len(dataset.columns), 'departuresDepartureDelay', label)\n",
    "\n",
    "\n",
    "# Get first month of Data\n",
    "number_of_months = 1\n",
    "index_slice = number_of_months * 4 * 24 * 31 - 1\n",
    "dataset = dataset.iloc[0:index_slice]\n",
    "\n",
    "\n",
    "# summarize first 5 rows\n",
    "display(dataset)\n",
    "\n",
    "\n",
    "# Normalize values\n",
    "values = dataset.values\n",
    "# display(values)\n",
    "X, y = values[:,:-1], values[:,-1]\n",
    "display(X)\n",
    "display(y)\n",
    "print(y.shape)\n",
    "print(type(X), type(y))\n",
    "\n",
    "\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(X)\n",
    "# display(scaled)\n",
    "y = y.reshape((len(y), 1))\n",
    "scaled = concatenate((X, y), axis=1)\n",
    "display(scaled)\n",
    "\n",
    "\n",
    "# frame as supervised learning\n",
    "number_of_time_steps = 1\n",
    "number_of_outputs = 1\n",
    "reframed = series_to_supervised(scaled, n_in=number_of_time_steps, n_out=number_of_outputs)\n",
    "\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[i for i in range(20,39)]], axis=1, inplace=True)  # I don't think we need this, but not sure\n",
    "display(reframed)\n",
    "\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "number_of_days_to_train = 20\n",
    "number_of_timeslots_in_one_hour = 4 # 4 for 15 minute intervals, 1 for 1 hour intervals\n",
    "train_index = number_of_days_to_train * 24 * number_of_timeslots_in_one_hour\n",
    "train = values[:train_index, :]\n",
    "test = values[train_index:, :]\n",
    "print('Shape of dataset:', reframed.shape)\n",
    "print('Shape of train dataset:', train.shape)\n",
    "print('Shape of test dataset:', test.shape)\n",
    "\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], -1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], -1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=75, batch_size=72, validation_data=(test_X, test_y), verbose=1, shuffle=False)\n",
    "\n",
    "\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "\n",
    "\n",
    "# calculate MAE\n",
    "mae = mean_absolute_error(test_y, yhat)\n",
    "print('Test MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a906fffd0068e70e9fb80d992d8da3d10a7e052a8ae415c1855a00961817ff15"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
