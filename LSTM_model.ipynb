{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from extraction.extract import *\n",
    "import math\n",
    "import numpy\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from datetime import datetime\n",
    "from scipy.stats import norm\n",
    "sys.path.append(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An LSTM model that trains on a time period of data in order to make a prediction at a predetermined time interval in the future is coded. Because LSTMs are designed to have a loockback interval where they look into the past to make a prediction in the future, a lot of data preparation must be done to be able to feed it to the model, as will be explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used for the LSTM model was generated with the external \"GenerateNNdata\". In order to make it compatible with the LSTM workframe the dataset had to be modified such that a certain number of past timesteps are used in order to predict a certain time in the future. The structure of the final version of the dataset is given by the \"series_to_supervised\" function, which takes care of only including data corresponding to the aforementioned timesteps. Moreover, the unnecessary columns ('departuresArrivalDelay' and 'arrivalsDepartureDelay') are dropped and the remaining ones are reordered such that the target features ('departuresDepartureDelay' and 'arrivalsArrivalDelay') are placed at the end. The data is also scaled and then further processed in order to drop the columns corresponding to future steps which we do not want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating NN data for EGLL with a timeslot length of 15 minutes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeslot</th>\n",
       "      <th>departing</th>\n",
       "      <th>arriving</th>\n",
       "      <th>lowcost</th>\n",
       "      <th>arrivalsFlightDuration</th>\n",
       "      <th>arrivalsDepartureDelay</th>\n",
       "      <th>arrivalsArrivalDelay</th>\n",
       "      <th>departuresFlightDuration</th>\n",
       "      <th>departuresDepartureDelay</th>\n",
       "      <th>departuresArrivalDelay</th>\n",
       "      <th>...</th>\n",
       "      <th>capacityFilled</th>\n",
       "      <th>weekend</th>\n",
       "      <th>winter</th>\n",
       "      <th>spring</th>\n",
       "      <th>summer</th>\n",
       "      <th>autumn</th>\n",
       "      <th>night</th>\n",
       "      <th>morning</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>evening</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-01 00:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-01 00:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-01 00:45:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>2018-03-30 22:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>2018-03-30 23:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>2018-03-30 23:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>2018-03-30 23:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>2018-03-30 23:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2880 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timeslot  departing  arriving  lowcost  \\\n",
       "0    2018-03-01 00:00:00          1         0      0.0   \n",
       "1    2018-03-01 00:15:00          1         0      0.0   \n",
       "2    2018-03-01 00:30:00          1         0      0.0   \n",
       "3    2018-03-01 00:45:00          1         1      0.0   \n",
       "4    2018-03-01 01:00:00          1         0      0.0   \n",
       "...                  ...        ...       ...      ...   \n",
       "2875 2018-03-30 22:45:00          0         0      0.0   \n",
       "2876 2018-03-30 23:00:00          0         1      0.0   \n",
       "2877 2018-03-30 23:15:00          0         0      0.0   \n",
       "2878 2018-03-30 23:30:00          0         0      0.0   \n",
       "2879 2018-03-30 23:45:00          0         0      0.0   \n",
       "\n",
       "      arrivalsFlightDuration  arrivalsDepartureDelay  arrivalsArrivalDelay  \\\n",
       "0                        0.0                     0.0                   0.0   \n",
       "1                        0.0                     0.0                   0.0   \n",
       "2                        0.0                     0.0                   0.0   \n",
       "3                       53.0                    -4.0                 -14.0   \n",
       "4                        0.0                     0.0                   0.0   \n",
       "...                      ...                     ...                   ...   \n",
       "2875                     0.0                     0.0                   0.0   \n",
       "2876                    61.0                    17.0                  28.0   \n",
       "2877                     0.0                     0.0                   0.0   \n",
       "2878                     0.0                     0.0                   0.0   \n",
       "2879                     0.0                     0.0                   0.0   \n",
       "\n",
       "      departuresFlightDuration  departuresDepartureDelay  \\\n",
       "0                        402.0                      24.0   \n",
       "1                        388.0                     -20.0   \n",
       "2                        260.0                      -4.0   \n",
       "3                        249.0                      10.0   \n",
       "4                        408.0                     -14.0   \n",
       "...                        ...                       ...   \n",
       "2875                       0.0                       0.0   \n",
       "2876                       0.0                       0.0   \n",
       "2877                       0.0                       0.0   \n",
       "2878                       0.0                       0.0   \n",
       "2879                       0.0                       0.0   \n",
       "\n",
       "      departuresArrivalDelay  ...  capacityFilled  weekend  winter  spring  \\\n",
       "0                       62.0  ...        0.011364        0       0       1   \n",
       "1                      -25.0  ...        0.011364        0       0       1   \n",
       "2                       -7.0  ...        0.011364        0       0       1   \n",
       "3                       36.0  ...        0.022727        0       0       1   \n",
       "4                      -24.0  ...        0.011364        0       0       1   \n",
       "...                      ...  ...             ...      ...     ...     ...   \n",
       "2875                     0.0  ...        0.000000        0       0       1   \n",
       "2876                     0.0  ...        0.011364        0       0       1   \n",
       "2877                     0.0  ...        0.000000        0       0       1   \n",
       "2878                     0.0  ...        0.000000        0       0       1   \n",
       "2879                     0.0  ...        0.000000        0       0       1   \n",
       "\n",
       "      summer  autumn  night  morning  afternoon  evening  \n",
       "0          0       0      1        0          0        0  \n",
       "1          0       0      1        0          0        0  \n",
       "2          0       0      1        0          0        0  \n",
       "3          0       0      1        0          0        0  \n",
       "4          0       0      1        0          0        0  \n",
       "...      ...     ...    ...      ...        ...      ...  \n",
       "2875       0       0      0        0          0        1  \n",
       "2876       0       0      0        0          0        1  \n",
       "2877       0       0      0        0          0        1  \n",
       "2878       0       0      0        0          0        1  \n",
       "2879       0       0      0        0          0        1  \n",
       "\n",
       "[2880 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating NN data for EGLL with a timeslot length of 15 minutes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>departing</th>\n",
       "      <th>arriving</th>\n",
       "      <th>lowcost</th>\n",
       "      <th>arrivalsFlightDuration</th>\n",
       "      <th>arrivalsDepartureDelay</th>\n",
       "      <th>departuresFlightDuration</th>\n",
       "      <th>departuresArrivalDelay</th>\n",
       "      <th>planes</th>\n",
       "      <th>capacityFilled</th>\n",
       "      <th>weekend</th>\n",
       "      <th>winter</th>\n",
       "      <th>spring</th>\n",
       "      <th>summer</th>\n",
       "      <th>autumn</th>\n",
       "      <th>night</th>\n",
       "      <th>morning</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>evening</th>\n",
       "      <th>departuresDepartureDelay</th>\n",
       "      <th>arrivalsArrivalDelay</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timeslot</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:15:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:30:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:45:00</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-30 22:45:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-30 23:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-30 23:15:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-30 23:30:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-30 23:45:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2880 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     departing  arriving  lowcost  arrivalsFlightDuration  \\\n",
       "timeslot                                                                    \n",
       "2018-03-01 00:00:00          1         0      0.0                     0.0   \n",
       "2018-03-01 00:15:00          1         0      0.0                     0.0   \n",
       "2018-03-01 00:30:00          1         0      0.0                     0.0   \n",
       "2018-03-01 00:45:00          1         1      0.0                    53.0   \n",
       "2018-03-01 01:00:00          1         0      0.0                     0.0   \n",
       "...                        ...       ...      ...                     ...   \n",
       "2018-03-30 22:45:00          0         0      0.0                     0.0   \n",
       "2018-03-30 23:00:00          0         1      0.0                    61.0   \n",
       "2018-03-30 23:15:00          0         0      0.0                     0.0   \n",
       "2018-03-30 23:30:00          0         0      0.0                     0.0   \n",
       "2018-03-30 23:45:00          0         0      0.0                     0.0   \n",
       "\n",
       "                     arrivalsDepartureDelay  departuresFlightDuration  \\\n",
       "timeslot                                                                \n",
       "2018-03-01 00:00:00                     0.0                     402.0   \n",
       "2018-03-01 00:15:00                     0.0                     388.0   \n",
       "2018-03-01 00:30:00                     0.0                     260.0   \n",
       "2018-03-01 00:45:00                    -4.0                     249.0   \n",
       "2018-03-01 01:00:00                     0.0                     408.0   \n",
       "...                                     ...                       ...   \n",
       "2018-03-30 22:45:00                     0.0                       0.0   \n",
       "2018-03-30 23:00:00                    17.0                       0.0   \n",
       "2018-03-30 23:15:00                     0.0                       0.0   \n",
       "2018-03-30 23:30:00                     0.0                       0.0   \n",
       "2018-03-30 23:45:00                     0.0                       0.0   \n",
       "\n",
       "                     departuresArrivalDelay  planes  capacityFilled  weekend  \\\n",
       "timeslot                                                                       \n",
       "2018-03-01 00:00:00                    62.0      -1        0.011364        0   \n",
       "2018-03-01 00:15:00                   -25.0      -1        0.011364        0   \n",
       "2018-03-01 00:30:00                    -7.0      -1        0.011364        0   \n",
       "2018-03-01 00:45:00                    36.0       0        0.022727        0   \n",
       "2018-03-01 01:00:00                   -24.0      -1        0.011364        0   \n",
       "...                                     ...     ...             ...      ...   \n",
       "2018-03-30 22:45:00                     0.0       0        0.000000        0   \n",
       "2018-03-30 23:00:00                     0.0       1        0.011364        0   \n",
       "2018-03-30 23:15:00                     0.0       0        0.000000        0   \n",
       "2018-03-30 23:30:00                     0.0       0        0.000000        0   \n",
       "2018-03-30 23:45:00                     0.0       0        0.000000        0   \n",
       "\n",
       "                     winter  spring  summer  autumn  night  morning  \\\n",
       "timeslot                                                              \n",
       "2018-03-01 00:00:00       0       1       0       0      1        0   \n",
       "2018-03-01 00:15:00       0       1       0       0      1        0   \n",
       "2018-03-01 00:30:00       0       1       0       0      1        0   \n",
       "2018-03-01 00:45:00       0       1       0       0      1        0   \n",
       "2018-03-01 01:00:00       0       1       0       0      1        0   \n",
       "...                     ...     ...     ...     ...    ...      ...   \n",
       "2018-03-30 22:45:00       0       1       0       0      0        0   \n",
       "2018-03-30 23:00:00       0       1       0       0      0        0   \n",
       "2018-03-30 23:15:00       0       1       0       0      0        0   \n",
       "2018-03-30 23:30:00       0       1       0       0      0        0   \n",
       "2018-03-30 23:45:00       0       1       0       0      0        0   \n",
       "\n",
       "                     afternoon  evening  departuresDepartureDelay  \\\n",
       "timeslot                                                            \n",
       "2018-03-01 00:00:00          0        0                      24.0   \n",
       "2018-03-01 00:15:00          0        0                     -20.0   \n",
       "2018-03-01 00:30:00          0        0                      -4.0   \n",
       "2018-03-01 00:45:00          0        0                      10.0   \n",
       "2018-03-01 01:00:00          0        0                     -14.0   \n",
       "...                        ...      ...                       ...   \n",
       "2018-03-30 22:45:00          0        1                       0.0   \n",
       "2018-03-30 23:00:00          0        1                       0.0   \n",
       "2018-03-30 23:15:00          0        1                       0.0   \n",
       "2018-03-30 23:30:00          0        1                       0.0   \n",
       "2018-03-30 23:45:00          0        1                       0.0   \n",
       "\n",
       "                     arrivalsArrivalDelay  \n",
       "timeslot                                   \n",
       "2018-03-01 00:00:00                   0.0  \n",
       "2018-03-01 00:15:00                   0.0  \n",
       "2018-03-01 00:30:00                   0.0  \n",
       "2018-03-01 00:45:00                 -14.0  \n",
       "2018-03-01 01:00:00                   0.0  \n",
       "...                                   ...  \n",
       "2018-03-30 22:45:00                   0.0  \n",
       "2018-03-30 23:00:00                  28.0  \n",
       "2018-03-30 23:15:00                   0.0  \n",
       "2018-03-30 23:30:00                   0.0  \n",
       "2018-03-30 23:45:00                   0.0  \n",
       "\n",
       "[2880 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-12)</th>\n",
       "      <th>var2(t-12)</th>\n",
       "      <th>var3(t-12)</th>\n",
       "      <th>var4(t-12)</th>\n",
       "      <th>var5(t-12)</th>\n",
       "      <th>var6(t-12)</th>\n",
       "      <th>var7(t-12)</th>\n",
       "      <th>var8(t-12)</th>\n",
       "      <th>var9(t-12)</th>\n",
       "      <th>var10(t-12)</th>\n",
       "      <th>...</th>\n",
       "      <th>var11(t)</th>\n",
       "      <th>var12(t)</th>\n",
       "      <th>var13(t)</th>\n",
       "      <th>var14(t)</th>\n",
       "      <th>var15(t)</th>\n",
       "      <th>var16(t)</th>\n",
       "      <th>var17(t)</th>\n",
       "      <th>var18(t)</th>\n",
       "      <th>var19(t+11)</th>\n",
       "      <th>var20(t+11)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.498141</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.480793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660256</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.322181</td>\n",
       "      <td>0.185567</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.559829</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064139</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.308550</td>\n",
       "      <td>0.628866</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.505576</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.105630</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.205535</td>\n",
       "      <td>0.335395</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.325534</td>\n",
       "      <td>0.368333</td>\n",
       "      <td>0.270422</td>\n",
       "      <td>0.325932</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.541176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248084</td>\n",
       "      <td>0.275556</td>\n",
       "      <td>0.171692</td>\n",
       "      <td>0.320733</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.203442</td>\n",
       "      <td>0.361481</td>\n",
       "      <td>0.134862</td>\n",
       "      <td>0.283505</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.344086</td>\n",
       "      <td>0.228116</td>\n",
       "      <td>0.411852</td>\n",
       "      <td>0.323039</td>\n",
       "      <td>0.331483</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2857 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var1(t-12)  var2(t-12)  var3(t-12)  var4(t-12)  var5(t-12)  var6(t-12)  \\\n",
       "12      0.052632        0.00    0.000000    0.000000    0.240000    0.498141   \n",
       "13      0.052632        0.00    0.000000    0.000000    0.240000    0.480793   \n",
       "14      0.052632        0.00    0.000000    0.000000    0.240000    0.322181   \n",
       "15      0.052632        0.05    0.000000    0.064139    0.186667    0.308550   \n",
       "16      0.052632        0.00    0.000000    0.000000    0.240000    0.505576   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2864    0.789474        0.35    0.242424    0.105630    0.314286    0.205535   \n",
       "2865    0.684211        0.40    0.253968    0.325534    0.368333    0.270422   \n",
       "2866    0.473684        0.30    0.000000    0.248084    0.275556    0.171692   \n",
       "2867    0.315789        0.45    0.177778    0.203442    0.361481    0.134862   \n",
       "2868    0.684211        0.90    0.344086    0.228116    0.411852    0.323039   \n",
       "\n",
       "      var7(t-12)  var8(t-12)  var9(t-12)  var10(t-12)  ...  var11(t)  \\\n",
       "12      0.896907    0.428571    0.030303          0.0  ...       0.0   \n",
       "13      0.000000    0.428571    0.030303          0.0  ...       0.0   \n",
       "14      0.185567    0.428571    0.030303          0.0  ...       0.0   \n",
       "15      0.628866    0.464286    0.060606          0.0  ...       0.0   \n",
       "16      0.010309    0.428571    0.030303          0.0  ...       0.0   \n",
       "...          ...         ...         ...          ...  ...       ...   \n",
       "2864    0.335395    0.178571    0.666667          0.0  ...       0.0   \n",
       "2865    0.325932    0.285714    0.636364          0.0  ...       0.0   \n",
       "2866    0.320733    0.357143    0.454545          0.0  ...       0.0   \n",
       "2867    0.283505    0.571429    0.454545          0.0  ...       0.0   \n",
       "2868    0.331483    0.642857    0.939394          0.0  ...       0.0   \n",
       "\n",
       "      var12(t)  var13(t)  var14(t)  var15(t)  var16(t)  var17(t)  var18(t)  \\\n",
       "12         0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "13         0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "14         0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "15         0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "16         0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2864       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2865       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2866       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2867       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2868       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "\n",
       "      var19(t+11)  var20(t+11)  \n",
       "12       0.269231     0.211765  \n",
       "13       0.660256     0.800000  \n",
       "14       0.559829     0.211765  \n",
       "15       0.533333     0.211765  \n",
       "16       0.512821     0.211765  \n",
       "...           ...          ...  \n",
       "2864     0.269231     0.211765  \n",
       "2865     0.269231     0.541176  \n",
       "2866     0.269231     0.211765  \n",
       "2867     0.269231     0.211765  \n",
       "2868     0.269231     0.211765  \n",
       "\n",
       "[2857 rows x 260 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-12)</th>\n",
       "      <th>var2(t-12)</th>\n",
       "      <th>var3(t-12)</th>\n",
       "      <th>var4(t-12)</th>\n",
       "      <th>var5(t-12)</th>\n",
       "      <th>var6(t-12)</th>\n",
       "      <th>var7(t-12)</th>\n",
       "      <th>var8(t-12)</th>\n",
       "      <th>var9(t-12)</th>\n",
       "      <th>var10(t-12)</th>\n",
       "      <th>...</th>\n",
       "      <th>var11(t)</th>\n",
       "      <th>var12(t)</th>\n",
       "      <th>var13(t)</th>\n",
       "      <th>var14(t)</th>\n",
       "      <th>var15(t)</th>\n",
       "      <th>var16(t)</th>\n",
       "      <th>var17(t)</th>\n",
       "      <th>var18(t)</th>\n",
       "      <th>var19(t+11)</th>\n",
       "      <th>var20(t+11)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257732</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.550980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256555</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.161710</td>\n",
       "      <td>0.613402</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.633484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.105741</td>\n",
       "      <td>0.570447</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.477564</td>\n",
       "      <td>0.662353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.132342</td>\n",
       "      <td>0.470103</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.381410</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.085295</td>\n",
       "      <td>0.537801</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.677941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.105630</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.205535</td>\n",
       "      <td>0.335395</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.325534</td>\n",
       "      <td>0.368333</td>\n",
       "      <td>0.270422</td>\n",
       "      <td>0.325932</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.541176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248084</td>\n",
       "      <td>0.275556</td>\n",
       "      <td>0.171692</td>\n",
       "      <td>0.320733</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.203442</td>\n",
       "      <td>0.361481</td>\n",
       "      <td>0.134862</td>\n",
       "      <td>0.283505</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.344086</td>\n",
       "      <td>0.228116</td>\n",
       "      <td>0.411852</td>\n",
       "      <td>0.323039</td>\n",
       "      <td>0.331483</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1967 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var1(t-12)  var2(t-12)  var3(t-12)  var4(t-12)  var5(t-12)  var6(t-12)  \\\n",
       "35      0.000000        0.00    0.000000    0.000000    0.240000    0.000000   \n",
       "36      0.105263        0.05    0.000000    0.256555    0.746667    0.161710   \n",
       "37      0.157895        0.00    0.000000    0.000000    0.240000    0.105741   \n",
       "38      0.263158        0.00    0.000000    0.000000    0.240000    0.132342   \n",
       "39      0.315789        0.00    0.000000    0.000000    0.240000    0.085295   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2864    0.789474        0.35    0.242424    0.105630    0.314286    0.205535   \n",
       "2865    0.684211        0.40    0.253968    0.325534    0.368333    0.270422   \n",
       "2866    0.473684        0.30    0.000000    0.248084    0.275556    0.171692   \n",
       "2867    0.315789        0.45    0.177778    0.203442    0.361481    0.134862   \n",
       "2868    0.684211        0.90    0.344086    0.228116    0.411852    0.323039   \n",
       "\n",
       "      var7(t-12)  var8(t-12)  var9(t-12)  var10(t-12)  ...  var11(t)  \\\n",
       "35      0.257732    0.464286    0.000000          0.0  ...       0.0   \n",
       "36      0.613402    0.428571    0.090909          0.0  ...       0.0   \n",
       "37      0.570447    0.357143    0.090909          0.0  ...       0.0   \n",
       "38      0.470103    0.285714    0.151515          0.0  ...       0.0   \n",
       "39      0.537801    0.250000    0.181818          0.0  ...       0.0   \n",
       "...          ...         ...         ...          ...  ...       ...   \n",
       "2864    0.335395    0.178571    0.666667          0.0  ...       0.0   \n",
       "2865    0.325932    0.285714    0.636364          0.0  ...       0.0   \n",
       "2866    0.320733    0.357143    0.454545          0.0  ...       0.0   \n",
       "2867    0.283505    0.571429    0.454545          0.0  ...       0.0   \n",
       "2868    0.331483    0.642857    0.939394          0.0  ...       0.0   \n",
       "\n",
       "      var12(t)  var13(t)  var14(t)  var15(t)  var16(t)  var17(t)  var18(t)  \\\n",
       "35         0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n",
       "36         0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n",
       "37         0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n",
       "38         0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n",
       "39         0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2864       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2865       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2866       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2867       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2868       0.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "\n",
       "      var19(t+11)  var20(t+11)  \n",
       "35       0.562500     0.550980  \n",
       "36       0.615385     0.633484  \n",
       "37       0.477564     0.662353  \n",
       "38       0.381410     0.680000  \n",
       "39       0.545455     0.677941  \n",
       "...           ...          ...  \n",
       "2864     0.269231     0.211765  \n",
       "2865     0.269231     0.541176  \n",
       "2866     0.269231     0.211765  \n",
       "2867     0.269231     0.211765  \n",
       "2868     0.269231     0.211765  \n",
       "\n",
       "[1967 rows x 260 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "\n",
    "# Generate single airport data and move target labels to the last 2 columns \n",
    "dataset = generateNNdata(\"EGLL\", timeslotLength=15, catagoricalFlightDuration=False, start=datetime(2018, 3, 1), end=datetime(2018, 3, 31), forceRegenerateData=True)\n",
    "display(dataset)\n",
    "dataset = dataset.set_index(\"timeslot\")\n",
    "dataset.drop(columns=['departuresArrivalDelay','arrivalsDepartureDelay'])\n",
    "label1 = dataset.pop('departuresDepartureDelay')\n",
    "dataset.insert(len(dataset.columns), 'departuresDepartureDelay', label1)\n",
    "label2 = dataset.pop('arrivalsArrivalDelay')\n",
    "dataset.insert(len(dataset.columns), 'arrivalsArrivalDelay', label2)\n",
    "# display(dataset)\n",
    "test_dataset = generateNNdata(\"EGLL\", timeslotLength=15, catagoricalFlightDuration=False, start=datetime(2018, 6, 1), end=datetime(2018, 6, 30), forceRegenerateData=True)\n",
    "test_dataset = test_dataset.set_index(\"timeslot\")\n",
    "test_dataset.drop(columns=['departuresArrivalDelay','arrivalsDepartureDelay'])\n",
    "label1 = test_dataset.pop('departuresDepartureDelay')\n",
    "test_dataset.insert(len(test_dataset.columns), 'departuresDepartureDelay', label1)\n",
    "label2 = test_dataset.pop('arrivalsArrivalDelay')\n",
    "test_dataset.insert(len(test_dataset.columns), 'arrivalsArrivalDelay', label2)\n",
    "\n",
    "display(dataset)\n",
    "\n",
    "# Normalize values\n",
    "values = dataset.values\n",
    "test_values = test_dataset.values\n",
    "\n",
    "\n",
    "# Ensure all data is float\n",
    "values = values.astype('float32')\n",
    "test_values = test_values.astype('float32')\n",
    "\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "test_scaled = scaler.fit_transform(test_values)\n",
    "# display(scaled)\n",
    "\n",
    "\n",
    "# Frame as supervised learning\n",
    "number_of_past_steps = 12\n",
    "number_of_future_steps = 12\n",
    "# number_of_future_steps2 = 6\n",
    "number_of_outputs = 2\n",
    "reframed = series_to_supervised(scaled, n_in=number_of_past_steps, n_out=number_of_future_steps)\n",
    "test_reframed = series_to_supervised(test_scaled, n_in=number_of_past_steps, n_out=number_of_future_steps)\n",
    "\n",
    "\n",
    "# Create a list of column names to drop\n",
    "column_drop_lst = []\n",
    "for timestep in range(number_of_future_steps):\n",
    "    for variable in range(1, len(dataset.columns) + 1):\n",
    "        if timestep == 0:\n",
    "            if variable > len(dataset.columns) - number_of_outputs:\n",
    "                column_drop_lst.append(f\"var{variable}(t)\")\n",
    "        elif timestep == number_of_future_steps-1 and variable > len(dataset.columns) - number_of_outputs:\n",
    "            pass\n",
    "        else:\n",
    "            column_drop_lst.append(f\"var{variable}(t+{timestep})\")\n",
    "\n",
    "# column_drop_lst.remove(f'var19(t+{number_of_future_steps2-1})')\n",
    "# column_drop_lst.remove(f'var20(t+{number_of_future_steps2-1})')\n",
    "\n",
    "\n",
    "# Drop columns we don't want to predict\n",
    "reframed.drop(columns=reframed[column_drop_lst], inplace=True)\n",
    "test_reframed.drop(columns=test_reframed[column_drop_lst], inplace=True)\n",
    "display(reframed)\n",
    "# display(test_reframed)\n",
    "\n",
    "\n",
    "# Remove rows that contain variables of night\n",
    "for timestep in range(1, number_of_past_steps):\n",
    "    reframed = reframed.query(f'`var1(t-{timestep})` != 0 | `var2(t-{timestep})` != 0')\n",
    "\n",
    "for timestep in range(1, number_of_past_steps):\n",
    "    no_night_reframed = test_reframed.query(f'`var1(t-{timestep})` != 0 | `var2(t-{timestep})` != 0')\n",
    "\n",
    "display(reframed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE AND FIT INITIAL MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can be seen below is the splitting of the data into the training and the test sets. Out of the one month worth of data, 600 hours are used for training and the rest are used for testing. After reshaping the sets into the desired form for the proper functioning of the LSTM, the data is fitted on a single-layer LSTM model. After iterating multiple times for different numbers of epochs, we decided that 50 epochs are enough, since the errors did not change significantly after this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 1, 200)            271200    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1, 200)            0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 1, 400)            961600    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1, 400)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1, 50)             20050     \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 1, 800)            2723200   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1, 50)             40050     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 300)               421200    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 25)                7525      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 4,445,107\n",
      "Trainable params: 4,445,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test MAE1: 1.085\n",
      "Test MAE2: 1.395\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "values = reframed.values\n",
    "test_values = test_reframed.values\n",
    "no_night_values = no_night_reframed.values\n",
    "val_ratio = 0.3\n",
    "train_index = int(val_ratio * len(reframed))\n",
    "\n",
    "\n",
    "# Split into train and test sets\n",
    "train = values[:(train_index), :]\n",
    "val = values[train_index:, :]\n",
    "test = test_values\n",
    "no_night = no_night_values\n",
    "\n",
    "# Split into input and outputs\n",
    "train_X, train_y = train[:, :-2], train[:, -2:]\n",
    "val_X, val_y = val[:, :-2], val[:, -2:]\n",
    "test_X, test_y = test[:, :-2], test[:, -2:]\n",
    "no_night_X, no_night_y = no_night[:, :-2], no_night[:, -2:]\n",
    "\n",
    "\n",
    "# Reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], -1, train_X.shape[1]))\n",
    "val_X = val_X.reshape((val_X.shape[0], -1, val_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], -1, test_X.shape[1]))\n",
    "no_night_X = no_night_X.reshape((no_night_X.shape[0], -1, no_night_X.shape[1]))\n",
    "\n",
    "# Design LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(LSTM(400, return_sequences=True))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(50))\n",
    "model.add(LSTM(800, return_sequences=True))\n",
    "model.add(Dense(50))\n",
    "model.add(LSTM(300))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(25))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(2))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Fit data\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data = (test_X, test_y), verbose=0, shuffle=False)\n",
    "\n",
    "\n",
    "# Accuracies of seperate month of data\n",
    "# all_times_accuracy = model.evaluate(test_X, test_y)\n",
    "# no_night_accuracy = model.evaluate(no_night_X, no_night_y)\n",
    "# print(\"Accuracy of all data of June:\", round(all_times_accuracy,5))\n",
    "# print(\"Accuracy of no night data of June:\", round(no_night_accuracy, 5))\n",
    "\n",
    "\n",
    "# Generate predictions\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "\n",
    "# Split and reshape the two desired outputs in separate arrays to prepare for inverse scaling\n",
    "yhat1 = yhat[:, 0]\n",
    "yhat2 = yhat[:, 1]\n",
    "yhat1 = yhat1.reshape(len(yhat), 1)\n",
    "yhat2 = yhat2.reshape(len(yhat), 1)\n",
    "\n",
    "\n",
    "# Also split the real values of the labels and reshape for inverse scaling\n",
    "test_y_1 = test_y[:, 0]\n",
    "test_y_2 = test_y[:, 1]\n",
    "test_y_1 = test_y_1.reshape(len(test_y), 1)\n",
    "test_y_2 = test_y_2.reshape(len(test_y), 1)\n",
    "\n",
    "\n",
    "# Inverse transform the predictions\n",
    "inv_yhat_1 = concatenate((yhat1, yhat2, test_X[:, 0:18]), axis=1)\n",
    "inv_yhat_1 = scaler.inverse_transform(inv_yhat_1)\n",
    "inv_yhat_1 = inv_yhat_1[:, :2]\n",
    "\n",
    "\n",
    "# Inverse transform the real values of the labels\n",
    "inv_y_1 = concatenate((test_y_1, test_y_2, test_X[:, 0:18]), axis=1)\n",
    "inv_y_1 = scaler.inverse_transform(inv_y_1)\n",
    "inv_y_1 = inv_y_1[:, :2]\n",
    "\n",
    "\n",
    "# calculate MAE between predicted and actual labels\n",
    "mae1 = mean_absolute_error(inv_y_1[:, 0], inv_yhat_1[:, 0])\n",
    "mae2 = mean_absolute_error(inv_y_1[:, 1], inv_yhat_1[:, 1])\n",
    "\n",
    "\n",
    "print('Test MAE1: %.3f' % mae1)\n",
    "print('Test MAE2: %.3f' % mae2)\n",
    "\n",
    "\n",
    "# Plot loss\n",
    "plt.title(\"Loss vs Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "pyplot.plot(history.history['loss'], label='Train Loss')\n",
    "pyplot.plot(history.history['val_loss'], label='Validation Loss')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(LSTM(200, return_sequences=True))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(50))\n",
    "model.add(LSTM(400, return_sequences=True))\n",
    "model.add(Dense(50))\n",
    "model.add(LSTM(200))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(25))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(2))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# model.summary()\n",
    "\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data = (val_X, val_y), verbose=0, shuffle=False) #validation_data=(val_X, val_y),\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae1_lst = []\n",
    "# mae2_lst = []\n",
    "lookahead_lst = numpy.arange(3, 14, 2) \n",
    "number_of_past_steps = 6\n",
    "\n",
    "\n",
    "for lookahead in lookahead_lst:\n",
    "\n",
    "    number_of_future_steps = lookahead  \n",
    "    reframed = series_to_supervised(scaled, n_in=number_of_past_steps, n_out=number_of_future_steps)\n",
    "    test_reframed = series_to_supervised(test_scaled, n_in=number_of_past_steps, n_out=number_of_future_steps)\n",
    "\n",
    "\n",
    "    # Create a list of column names to drop\n",
    "    column_drop_lst = []\n",
    "    for timestep in range(number_of_future_steps):\n",
    "        for variable in range(1, len(dataset.columns) + 1):\n",
    "            if timestep == 0:\n",
    "                if variable > len(dataset.columns) - number_of_outputs:\n",
    "                    column_drop_lst.append(f\"var{variable}(t)\")\n",
    "            elif timestep == number_of_future_steps-1 and variable > len(dataset.columns) - number_of_outputs:\n",
    "                pass\n",
    "            else:\n",
    "                column_drop_lst.append(f\"var{variable}(t+{timestep})\")\n",
    "\n",
    "\n",
    "\n",
    "    # Drop columns we don't want to predict\n",
    "    reframed.drop(columns=reframed[column_drop_lst], inplace=True)\n",
    "    test_reframed.drop(columns=test_reframed[column_drop_lst], inplace=True)\n",
    "    # display(test_reframed)\n",
    "\n",
    "\n",
    "    # Remove rows that contain variables of night\n",
    "    for timestep in range(1, number_of_past_steps):\n",
    "        reframed = reframed.query(f'`var1(t-{timestep})` != 0 | `var2(t-{timestep})` != 0')\n",
    "\n",
    "    for timestep in range(1, number_of_past_steps):\n",
    "        no_night_reframed = test_reframed.query(f'`var1(t-{timestep})` != 0 | `var2(t-{timestep})` != 0')\n",
    "\n",
    "    # display(reframed)\n",
    "\n",
    "    \n",
    "    values = reframed.values\n",
    "    test_values = test_reframed.values\n",
    "    no_night_values = no_night_reframed.values\n",
    "    val_ratio = 0.3\n",
    "    train_index = int(val_ratio * len(reframed))\n",
    "\n",
    "\n",
    "    # Split into train and test sets\n",
    "    train = values[:(train_index), :]\n",
    "    val = values[train_index:, :]\n",
    "    test = test_values\n",
    "\n",
    "    # Split into input and outputs\n",
    "    train_X, train_y = train[:, :-2], train[:, -2:]\n",
    "    val_X, val_y = val[:, :-2], val[:, -2:]\n",
    "    test_X, test_y = test[:, :-2], test[:, -2:]\n",
    "\n",
    "\n",
    "    # Reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], -1, train_X.shape[1]))\n",
    "    val_X = val_X.reshape((val_X.shape[0], -1, val_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], -1, test_X.shape[1]))\n",
    "\n",
    "\n",
    "    # fit network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(LSTM(400, return_sequences=True))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(50))\n",
    "    model.add(LSTM(800, return_sequences=True))\n",
    "    model.add(Dense(50))\n",
    "    model.add(LSTM(300))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(2))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    # model.summary()\n",
    "\n",
    "    history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data = (val_X, val_y), verbose=0, shuffle=False) #validation_data=(val_X, val_y),\n",
    "\n",
    "\n",
    "\n",
    "    yhat = model.predict(test_X)\n",
    "    test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "\n",
    "    # Split and reshape the two desired outputs in separate arrays to prepare for inverse scaling\n",
    "    yhat1 = yhat[:, 0]\n",
    "    yhat2 = yhat[:, 1]\n",
    "    yhat1 = yhat1.reshape(len(yhat), 1)\n",
    "    yhat2 = yhat2.reshape(len(yhat), 1)\n",
    "\n",
    "\n",
    "    # Also split the real values of the labels and reshape for inverse scaling\n",
    "    test_y_1 = test_y[:, 0]\n",
    "    test_y_2 = test_y[:, 1]\n",
    "    test_y_1 = test_y_1.reshape(len(test_y), 1)\n",
    "    test_y_2 = test_y_2.reshape(len(test_y), 1)\n",
    "\n",
    "\n",
    "    # Inverse transform the predictions\n",
    "    inv_yhat_1 = concatenate((yhat1, yhat2, test_X[:, 0:18]), axis=1)\n",
    "    inv_yhat_1 = scaler.inverse_transform(inv_yhat_1)\n",
    "    inv_yhat_1 = inv_yhat_1[:, :2]\n",
    "\n",
    "\n",
    "    # Inverse transform the real values of the labels\n",
    "    inv_y_1 = concatenate((test_y_1, test_y_2, test_X[:, 0:18]), axis=1)\n",
    "    inv_y_1 = scaler.inverse_transform(inv_y_1)\n",
    "    inv_y_1 = inv_y_1[:, :2]\n",
    "\n",
    "\n",
    "    # calculate MAE between predicted and actual labels\n",
    "    # mae1 = mean_absolute_error(inv_y_1[:, 0], inv_yhat_1[:, 0])\n",
    "    # mae2 = mean_absolute_error(inv_y_1[:, 1], inv_yhat_1[:, 1])\n",
    "\n",
    "    data = {'departuresDepartureDelay Actual': inv_y_1[:, 0], 'departuresDepartureDelay Predicted': inv_yhat_1[:, 0], 'arrivalsArrivalDelay Actual': inv_y_1[:, 1], 'arrivalsArrivalDelay Predicted': inv_yhat_1[:, 1]}\n",
    "\n",
    "    results = pd.DataFrame(data)\n",
    "    # results = pd.DataFrame(inv_y_1[:, 0], inv_yhat_1[:, 0], inv_y_1[:, 1], inv_yhat_1[:, 1], columns = ['departuresDepartureDelay Actual', 'departuresDepartureDelay Predicted', 'arrivalsArrivalDelay Actual', 'arrivalsArrivalDelay Predicted'])\n",
    "    results.to_csv(f\"results_for_{(lookahead-1)/4}hrs\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Plot MAE vs lookback\n",
    "# plt.title(\"MAEs vs lookback\")\n",
    "# plt.plot(lookback_lst, mae1_lst, label = 'mae1')\n",
    "# plt.plot(lookback_lst, mae2_lst, label = 'mae2')\n",
    "# plt.xlabel(\"Lookback\")\n",
    "# plt.ylabel(\"MAE\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# print('minimum mae1 is {} for a lookback of {}'.format(numpy.min(mae1_lst), lookback_lst[mae1_lst.index(numpy.min(mae1_lst))]))\n",
    "# print('minimum mae2 is {} for a lookback of {}'. format(numpy.min(mae2_lst), lookback_lst[mae2_lst.index(numpy.min(mae2_lst))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two cells are used for tuning the number of neurons of the LSTM model and the look-back parameter (that is, how much back in time we go for training the LSTM), respectively. The mean absolute errors are plotted against both of these parameters and the minimums are found for each case. In order to keep the running time at an acceptable level, the two tunings are performed separately, in order to offer a general view on the best values of these parameters. It is also observed that the minimum values of the MAE's only vary by a very tiny amount, regardless of the parameters' values. The obtained results are also inverse scaled back to the initial scale for visualising them and for having the MAE's in the desired scale as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17828/3417315557.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# fit network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m72\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#validation_data=(val_X, val_y),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m-> 3038\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    981\u001b[0m           \u001b[1;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m           \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 983\u001b[1;33m             return autograph.converted_call(\n\u001b[0m\u001b[0;32m    984\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Allowlisted %s: from cache'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    462\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m    844\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1284\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1285\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1286\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2847\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2848\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2849\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2851\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3630\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3631\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3632\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3634\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m         \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    789\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n\u001b[0;32m    790\u001b[0m     \u001b[1;31m# Run backwards pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    792\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[1;31m# Collect metrics to return\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m     \"\"\"\n\u001b[1;32m--> 520\u001b[1;33m     grads_and_vars = self._compute_gradients(\n\u001b[0m\u001b[0;32m    521\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0;32m    522\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/gradients\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m       \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     self._assert_valid_dtypes([\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    452\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1082\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1085\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_backward_function\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    843\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_backward_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m       \u001b[0mcall_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 845\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rewrite_forward_and_call_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    846\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_backward_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_rewrite_forward_and_call_backward\u001b[1;34m(self, op, *doutputs)\u001b[0m\n\u001b[0;32m    758\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_rewrite_forward_and_call_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mdoutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;34m\"\"\"Add outputs to the forward call and feed them to the grad function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m     \u001b[0mforward_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackwards_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbackwards_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mbackwards_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructured_outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mforward_backward\u001b[1;34m(self, num_doutputs)\u001b[0m\n\u001b[0;32m    691\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mforward_backward\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m     \u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_forward_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_construct_forward_backward\u001b[1;34m(self, num_doutputs)\u001b[0m\n\u001b[0;32m    734\u001b[0m       backwards_graph = func_graph_module.FuncGraph(\n\u001b[0;32m    735\u001b[0m           _backward_name(self._func_graph.name))\n\u001b[1;32m--> 736\u001b[1;33m       func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m    737\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbackwards_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m           \u001b[0mpython_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_backprop_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_backprop_function\u001b[1;34m(*grad_ys)\u001b[0m\n\u001b[0;32m    725\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_backprop_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         return gradients_util._GradientsHelper(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    728\u001b[0m             \u001b[0mtrainable_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    679\u001b[0m                 \u001b[1;31m# If grad_fn was found, do not use SymbolicGradient even for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0m\u001b[0;32m    682\u001b[0m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0;32m    683\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Exit early\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m   \u001b[1;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 682\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    683\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py\u001b[0m in \u001b[0;36m_StridedSliceGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    273\u001b[0m   \u001b[1;31m# We could choose any of {begin|end|strides}.dtype since they are required to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m   \u001b[1;31m# be the same.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m   \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m   \u001b[0mx_static\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[1;34m(input, name, out_type)\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m   \"\"\"\n\u001b[1;32m--> 651\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[1;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[0;32m    677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 679\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[1;34m(input, out_type, name)\u001b[0m\n\u001b[0;32m   9196\u001b[0m     \u001b[0mout_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9197\u001b[0m   \u001b[0mout_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"out_type\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9198\u001b[1;33m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[0;32m   9199\u001b[0m         \"Shape\", input=input, out_type=out_type, name=name)\n\u001b[0;32m   9200\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    746\u001b[0m       \u001b[1;31m# Add Op to graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[0;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    595\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mctxt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"AddValue\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAddValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m       \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mcapture\u001b[1;34m(self, tensor, name, shape)\u001b[0m\n\u001b[0;32m    647\u001b[0m               % (tensor, tensor.graph, self))\n\u001b[0;32m    648\u001b[0m         \u001b[0minner_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_capture_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_capture_helper\u001b[1;34m(self, tensor, name, shape)\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[0mcapture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_captures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcapture\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m       placeholder = _create_substitute_placeholder(\n\u001b[0m\u001b[0;32m    656\u001b[0m           tensor, name=name, dtype=tensor.dtype, shape=shape)\n\u001b[0;32m    657\u001b[0m       \u001b[1;31m# Record the composite device as an attribute to the placeholder.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_substitute_placeholder\u001b[1;34m(value, name, dtype, shape)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m     placeholder = graph_placeholder(\n\u001b[0m\u001b[0;32m   1152\u001b[0m         dtype=dtype or value.dtype, shape=shape, name=name)\n\u001b[0;32m   1153\u001b[0m   \u001b[0mhandle_data_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\graph_only_ops.py\u001b[0m in \u001b[0;36mgraph_placeholder\u001b[1;34m(dtype, shape, name)\u001b[0m\n\u001b[0;32m     36\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m   op = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m     39\u001b[0m       \u001b[1;34m\"Placeholder\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m       attrs=attrs, name=name)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    600\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         compute_device)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3559\u001b[0m     \u001b[1;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3560\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3561\u001b[1;33m       ret = Operation(\n\u001b[0m\u001b[0;32m   3562\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3563\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2039\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2041\u001b[1;33m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[0;32m   2042\u001b[0m                                 control_input_ops, op_def)\n\u001b[0;32m   2043\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1879\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1880\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1881\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mae1_lst = []\n",
    "mae2_lst = []\n",
    "neurons_lst = numpy.arange(2, 300, 1)\n",
    "\n",
    "for neurons in neurons_lst:\n",
    "\n",
    "\n",
    "    # Design the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(LSTM(2*neurons, return_sequences=True))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(50))\n",
    "    model.add(LSTM(4*neurons, return_sequences=True))\n",
    "    model.add(Dense(50))\n",
    "    model.add(LSTM(2*neurons))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(2))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    # model.summary()\n",
    "\n",
    "\n",
    "    # fit network\n",
    "    history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data = (val_X, val_y), verbose=0, shuffle=False) #validation_data=(val_X, val_y),\n",
    "\n",
    "\n",
    "    # Generate predictions\n",
    "\n",
    "    yhat = model.predict(val_X)\n",
    "    reshaped_val_X = val_X.reshape((val_X.shape[0], val_X.shape[2]))\n",
    "\n",
    "\n",
    "    # Split and reshape the two desired outputs in separate arrays to prepare for inverse scaling\n",
    "    yhat1 = yhat[:, 0]\n",
    "    yhat2 = yhat[:, 1]\n",
    "    yhat1 = yhat1.reshape(len(yhat), 1)\n",
    "    yhat2 = yhat2.reshape(len(yhat), 1)\n",
    "\n",
    "\n",
    "    # Also split the real values of the labels and reshape for inverse scaling\n",
    "    val_y_1 = val_y[:, 0]\n",
    "    val_y_2 = val_y[:, 1]\n",
    "    val_y_1 = val_y_1.reshape(len(val_y), 1)\n",
    "    val_y_2 = val_y_2.reshape(len(val_y), 1)\n",
    "\n",
    "\n",
    "    # Inverse transform the predictions\n",
    "    inv_yhat_1 = concatenate((yhat1, yhat2, reshaped_val_X[:, 0:18]), axis=1)\n",
    "    inv_yhat_1 = scaler.inverse_transform(inv_yhat_1)\n",
    "    inv_yhat_1 = inv_yhat_1[:, :2]\n",
    "\n",
    "\n",
    "    # Inverse transform the real values of the labels\n",
    "    inv_y_1 = concatenate((val_y_1, val_y_2, reshaped_val_X[:, 0:18]), axis=1)\n",
    "    inv_y_1 = scaler.inverse_transform(inv_y_1)\n",
    "    inv_y_1 = inv_y_1[:, :2]\n",
    "\n",
    "\n",
    "    # calculate MAE between predicted and actual labels\n",
    "\n",
    "    mae1 = mean_absolute_error(inv_y_1[:, 0], inv_yhat_1[:, 0])\n",
    "    mae1_lst.append(mae1)\n",
    "    mae2 = mean_absolute_error(inv_y_1[:, 1], inv_yhat_1[:, 1])\n",
    "    mae2_lst.append(mae2)\n",
    "\n",
    "\n",
    "# Plot MAE vs neurons\n",
    "plt.title(\"MAE vs number of neurons\")\n",
    "plt.plot(neurons_lst, mae1_lst, label = 'mae1')\n",
    "plt.plot(neurons_lst, mae2_lst, label = 'mae2')\n",
    "plt.xlabel(\"Neurons\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('minimum mae1 is {} for a number of {} neurons'.format(numpy.min(mae1_lst), neurons_lst[mae1_lst.index(numpy.min(mae1_lst))]))\n",
    "print('minimum mae2 is {} for a number of {} neurons'. format(numpy.min(mae2_lst), neurons_lst[mae2_lst.index(numpy.min(mae2_lst))]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae1_lst = []\n",
    "mae2_lst = []\n",
    "lookback_lst = numpy.arange(1, 100, 1) \n",
    "number_of_future_steps = 6\n",
    "\n",
    "\n",
    "\n",
    "for lookback in lookback_lst:\n",
    "\n",
    "    number_of_past_steps = lookback  \n",
    "    reframed = series_to_supervised(scaled, n_in=number_of_past_steps, n_out=number_of_future_steps)\n",
    "\n",
    "    # drop columns we don't want to predict\n",
    "    reframed.drop(columns=reframed.columns[[i for i in range(len(reframed.columns)-20, len(reframed.columns)-2)]], inplace=True)\n",
    "    values = reframed.values\n",
    "    values = values.astype('float32')\n",
    "\n",
    "\n",
    "    # normalize features\n",
    "    number_of_hours_to_train = 600\n",
    "    number_of_timeslots_in_one_hour = 4 # 4 for 15 minute intervals, 1 for 1 hour intervals\n",
    "    train_index = number_of_hours_to_train * number_of_timeslots_in_one_hour\n",
    "\n",
    "\n",
    "    # split into train and validation sets\n",
    "    train = values[:(train_index), :]\n",
    "    val = values[train_index:, :]\n",
    "\n",
    "\n",
    "    # split into input and outputs\n",
    "    train_X, train_y = train[:, :-2], train[:, -2:]\n",
    "    val_X, val_y = val[:, :-2], val[:, -2:]\n",
    "\n",
    "\n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], -1, train_X.shape[1]))\n",
    "    val_X = val_X.reshape((val_X.shape[0], -1, val_X.shape[1]))\n",
    "\n",
    "    # fit network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(LSTM(400, return_sequences=True))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(50))\n",
    "    model.add(LSTM(800, return_sequences=True))\n",
    "    model.add(Dense(50))\n",
    "    model.add(LSTM(300))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(2))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    # model.summary()\n",
    "    \n",
    "    history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data = (val_X, val_y), verbose=0, shuffle=False) #validation_data=(val_X, val_y),\n",
    "\n",
    "\n",
    "    # Generate predictions\n",
    "    yhat = model.predict(val_X)\n",
    "    reshaped_val_X = val_X.reshape((val_X.shape[0], val_X.shape[2]))\n",
    "\n",
    "\n",
    "    # Split and reshape the two desired outputs in separate arrays to prepare for inverse scaling\n",
    "    yhat1 = yhat[:, 0]\n",
    "    yhat2 = yhat[:, 1]\n",
    "    yhat1 = yhat1.reshape(len(yhat), 1)\n",
    "    yhat2 = yhat2.reshape(len(yhat), 1)\n",
    "\n",
    "\n",
    "    # Split real values of the labels and reshape for inverse scaling\n",
    "    val_y_1 = val_y[:, 0]\n",
    "    val_y_2 = val_y[:, 1]\n",
    "    val_y_1 = val_y_1.reshape(len(val_y), 1)\n",
    "    val_y_2 = val_y_2.reshape(len(val_y), 1)\n",
    "\n",
    "\n",
    "    # Inverse transform the predictions\n",
    "    inv_yhat_1 = concatenate((yhat1, yhat2, reshaped_val_X[:, 0:18]), axis=1)\n",
    "    inv_yhat_1 = scaler.inverse_transform(inv_yhat_1)\n",
    "    inv_yhat_1 = inv_yhat_1[:, :2]\n",
    "\n",
    "\n",
    "    # Inverse transform the real values of the labels\n",
    "    inv_y_1 = concatenate((val_y_1, val_y_2, reshaped_val_X[:, 0:18]), axis=1)\n",
    "    inv_y_1 = scaler.inverse_transform(inv_y_1)\n",
    "    inv_y_1 = inv_y_1[:, :2]\n",
    "\n",
    "\n",
    "    # Calculate MAE between predicted and actual labels\n",
    "    mae1 = mean_absolute_error(inv_y_1[:, 0], inv_yhat_1[:, 0])\n",
    "    mae1_lst.append(mae1)\n",
    "    mae2 = mean_absolute_error(inv_y_1[:, 1], inv_yhat_1[:, 1])\n",
    "    mae2_lst.append(mae2)\n",
    "\n",
    "\n",
    "# Plot MAE vs lookback\n",
    "plt.title(\"MAEs vs lookback\")\n",
    "plt.plot(lookback_lst, mae1_lst, label = 'mae1')\n",
    "plt.plot(lookback_lst, mae2_lst, label = 'mae2')\n",
    "plt.xlabel(\"Lookback\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('minimum mae1 is {} for a lookback of {}'.format(numpy.min(mae1_lst), lookback_lst[mae1_lst.index(numpy.min(mae1_lst))]))\n",
    "print('minimum mae2 is {} for a lookback of {}'. format(numpy.min(mae2_lst), lookback_lst[mae2_lst.index(numpy.min(mae2_lst))]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION OF FINAL MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the final model consisting of the optimal obtained parameters (which can be seen below) is fitted and run again in order to obtain what should be the most accurate results as far as the performed tuning allows us to obtain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPTIMAL PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 10\n",
    "number_of_past_steps = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize values\n",
    "values = dataset.values\n",
    "# display(values)\n",
    "\n",
    "\n",
    "# Ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# print(scaled)\n",
    "\n",
    "# Frame as supervised learning\n",
    "number_of_future_steps = 12\n",
    "number_of_outputs = 2\n",
    "reframed = series_to_supervised(scaled, n_in=number_of_past_steps, n_out=number_of_future_steps)\n",
    "\n",
    "\n",
    "# Create a list of column names to drop\n",
    "column_drop_lst = []\n",
    "\n",
    "for timestep in range(number_of_future_steps):\n",
    "    for variable in range(1, len(dataset.columns) + 1):\n",
    "        if timestep == 0:\n",
    "            if variable > len(dataset.columns) - number_of_outputs:\n",
    "                column_drop_lst.append(f\"var{variable}(t)\")\n",
    "        elif timestep == number_of_future_steps-1 and variable > len(dataset.columns) - number_of_outputs:\n",
    "            pass\n",
    "        else:\n",
    "            column_drop_lst.append(f\"var{variable}(t+{timestep})\")\n",
    "# print(column_drop_lst)\n",
    "\n",
    "\n",
    "# Drop columns we don't want to predict\n",
    "reframed.drop(columns=reframed[column_drop_lst], inplace=True)\n",
    "\n",
    "\n",
    "display(reframed)\n",
    "\n",
    "\n",
    "# Train index calculation\n",
    "values = reframed.values\n",
    "number_of_hours_to_train = 600\n",
    "number_of_timeslots_in_one_hour = 4 # 4 for 15 minute intervals, 1 for 1 hour intervals\n",
    "train_index = number_of_hours_to_train * number_of_timeslots_in_one_hour\n",
    "\n",
    "\n",
    "# Split into train and test sets\n",
    "train = values[:(train_index), :]\n",
    "test = values[train_index:, :]\n",
    "\n",
    "\n",
    "# Split into input and outputs\n",
    "train_X, train_y = train[:, :-2], train[:, -2:]\n",
    "test_X, test_y = test[:, :-2], test[:, -2:]\n",
    "\n",
    "\n",
    "# Reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], -1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], -1, test_X.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DEFINE AND FIT THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design final model\n",
    "model = Sequential()\n",
    "model.add(LSTM(neurons, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(2))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "\n",
    "# Fit data\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data = (test_X, test_y), verbose=0, shuffle=False) #validation_data=(val_X, val_y),\n",
    "\n",
    "\n",
    "# Plot loss\n",
    "plt.title(\"Train and Validation loss vs Epochs\")\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='validation')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EVALUATE FINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "\n",
    "# Split and reshape the two desired outputs in separate arrays to prepare for inverse scaling\n",
    "yhat1 = yhat[:, 0]\n",
    "yhat2 = yhat[:, 1]\n",
    "yhat1 = yhat1.reshape(len(yhat), 1)\n",
    "yhat2 = yhat2.reshape(len(yhat), 1)\n",
    "\n",
    "\n",
    "# Also split the real values of the labels and reshape for inverse scaling\n",
    "test_y_1 = test_y[:, 0]\n",
    "test_y_2 = test_y[:, 1]\n",
    "test_y_1 = test_y_1.reshape(len(test_y), 1)\n",
    "test_y_2 = test_y_2.reshape(len(test_y), 1)\n",
    "\n",
    "\n",
    "# Inverse transform the predictions\n",
    "inv_yhat_1 = concatenate((yhat1, yhat2, test_X[:, 0:18]), axis=1)\n",
    "inv_yhat_1 = scaler.inverse_transform(inv_yhat_1)\n",
    "inv_yhat_1 = inv_yhat_1[:, :2]\n",
    "\n",
    "\n",
    "# Inverse transform the real values of the labels\n",
    "inv_y_1 = concatenate((test_y_1, test_y_2, test_X[:, 0:18]), axis=1)\n",
    "inv_y_1 = scaler.inverse_transform(inv_y_1)\n",
    "inv_y_1 = inv_y_1[:, :2]\n",
    "\n",
    "\n",
    "# calculate MAE between predicted and actual labels\n",
    "mae1 = mean_absolute_error(inv_y_1[:, 0], inv_yhat_1[:, 0])\n",
    "mae2 = mean_absolute_error(inv_y_1[:, 1], inv_yhat_1[:, 1])\n",
    "\n",
    "\n",
    "print('Test MAE1: %.3f' % mae1)\n",
    "print('Test MAE2: %.3f' % mae2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NON SCALED LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an attempt to see how the model would wok if we don't scale the outputs. However it's a bit outdated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "\n",
    "dataset = generateNNdata(\"EHAM\", timeslotLength=15, catagoricalFlightDuration=False)\n",
    "dataset = dataset.set_index(\"timeslot\")\n",
    "dataset.drop(columns=['departuresArrivalDelay','arrivalsArrivalDelay'])\n",
    "label = dataset.pop('departuresDepartureDelay')\n",
    "dataset.insert(len(dataset.columns), 'departuresDepartureDelay', label)\n",
    "\n",
    "\n",
    "# Get first month of Data\n",
    "number_of_months = 1\n",
    "index_slice = number_of_months * 4 * 24 * 31 - 1\n",
    "dataset = dataset.iloc[0:index_slice]\n",
    "\n",
    "\n",
    "# summarize first 5 rows\n",
    "display(dataset)\n",
    "\n",
    "\n",
    "# Normalize values\n",
    "values = dataset.values\n",
    "# display(values)\n",
    "X, y = values[:,:-1], values[:,-1]\n",
    "display(X)\n",
    "display(y)\n",
    "print(y.shape)\n",
    "print(type(X), type(y))\n",
    "\n",
    "\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(X)\n",
    "# display(scaled)\n",
    "y = y.reshape((len(y), 1))\n",
    "scaled = concatenate((X, y), axis=1)\n",
    "display(scaled)\n",
    "\n",
    "\n",
    "# frame as supervised learning\n",
    "number_of_time_steps = 1\n",
    "number_of_outputs = 1\n",
    "reframed = series_to_supervised(scaled, n_in=number_of_time_steps, n_out=number_of_outputs)\n",
    "\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[i for i in range(20,39)]], axis=1, inplace=True)  # I don't think we need this, but not sure\n",
    "display(reframed)\n",
    "\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "number_of_days_to_train = 20\n",
    "number_of_timeslots_in_one_hour = 4 # 4 for 15 minute intervals, 1 for 1 hour intervals\n",
    "train_index = number_of_days_to_train * 24 * number_of_timeslots_in_one_hour\n",
    "train = values[:train_index, :]\n",
    "test = values[train_index:, :]\n",
    "print('Shape of dataset:', reframed.shape)\n",
    "print('Shape of train dataset:', train.shape)\n",
    "print('Shape of test dataset:', test.shape)\n",
    "\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], -1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], -1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=75, batch_size=72, validation_data=(test_X, test_y), verbose=1, shuffle=False)\n",
    "\n",
    "\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "\n",
    "\n",
    "# calculate MAE\n",
    "mae = mean_absolute_error(test_y, yhat)\n",
    "print('Test MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a906fffd0068e70e9fb80d992d8da3d10a7e052a8ae415c1855a00961817ff15"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
