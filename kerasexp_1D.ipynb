{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import typing\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "\n",
    "from extraction.extract import generateNNdataMultiple\n",
    "from extraction.extractionvalues import *\n",
    "from extraction.extractadjacency import getAdjacencyMatrix, distance_weight_adjacency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = ICAOTOP10\n",
    "n_nodes = n_airports = len(airports)\n",
    "start = datetime(2019, 3, 29)\n",
    "end = datetime(2019, 3, 31)\n",
    "timeslotLength = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 83.56it/s]\n"
     ]
    }
   ],
   "source": [
    "dataDict = generateNNdataMultiple(\n",
    "            airports,\n",
    "            timeslotLength,\n",
    "            GNNFormat=True,\n",
    "            start=start,\n",
    "            end=end,\n",
    "        )\n",
    "\n",
    "times = (list(dataDict.values())[0][\"T\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Mean Shape (9,)\n",
      "Y Mean Shape (2,)\n",
      "T x N x F:  Xarray = (48, 10, 9) Yarray = (48, 20)\n"
     ]
    }
   ],
   "source": [
    "columnsToDrop = [\"weekend\", \"winter\", \"spring\", \"summer\", \"autumn\", \"night\", \"morning\", \"afternoon\"]\n",
    "# print(dataDict[\"EGLL\"][\"X\"].shape)\n",
    "Xlist = []\n",
    "Ylist = []\n",
    "for airport in airports:\n",
    "    # T x F\n",
    "    X = dataDict[airport][\"X\"].drop(columnsToDrop, axis=1).to_numpy()\n",
    "    Xlist.append(X)\n",
    "    \n",
    "    Y = dataDict[airport][\"Y\"].to_numpy()\n",
    "    Ylist.append(Y)\n",
    "\n",
    "\n",
    "Xlist = np.array(Xlist)\n",
    "Ylist = np.array(Ylist)\n",
    "\n",
    "# N x T x F\n",
    "Xarray = np.swapaxes(Xlist, 0, 1)\n",
    "Yarray = np.swapaxes(Ylist, 0, 1)\n",
    "\n",
    "# Reshape to a flat array that goes arrival then departure delay\n",
    "Yarray = np.reshape(Yarray, newshape=[len(times), len(airports)*2], order=\"F\")\n",
    "\n",
    "# print(Yarray.shape)\n",
    "# T x N x F\n",
    "\n",
    "# Normalise over the features\n",
    "Xmean, Xstd = X.mean(axis=0), X.std(axis=0)\n",
    "X = (X - Xmean) / Xstd\n",
    "print(\"X Mean Shape\", Xmean.shape)\n",
    "Ymean, Ystd = Y.mean(axis=0), Y.std(axis=0)\n",
    "Y = (Y - Ymean) / Ystd\n",
    "print(\"Y Mean Shape\", Ymean.shape)\n",
    "\n",
    "print(\"T x N x F: \", \"Xarray =\", Xarray.shape, \"Yarray =\", Yarray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[1 3 2 4]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2], [3,4]])\n",
    "print(a)\n",
    "print(a.flatten(order=\"F\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 33\n"
     ]
    }
   ],
   "source": [
    "train_split, val_split = 0.6, 0.1\n",
    "\n",
    "fullLength = len(times)\n",
    "train_idx = int(train_split * fullLength)\n",
    "val_idx = int((val_split + train_split) * fullLength)\n",
    "print(train_idx, val_idx)\n",
    "\n",
    "Xtrain, Xval, Xtest = Xarray[0:train_idx], Xarray[train_idx:val_idx], Xarray[val_idx::]\n",
    "Ytrain, Yval, Ytest = Yarray[0:train_idx], Yarray[train_idx:val_idx], Yarray[val_idx::]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CacheDataset shapes: ((None, None, 10, 9), (None, None, 20)), types: (tf.float64, tf.float64)>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "input_sequence_length = 12\n",
    "forecast_horizon = 3\n",
    "multi_horizon = False\n",
    "\n",
    "\n",
    "def create_tf_dataset(\n",
    "    data_array: np.ndarray,\n",
    "    target_array,\n",
    "    input_sequence_length: int,\n",
    "    forecast_horizon: int,\n",
    "    batch_size: int = 128,\n",
    "    shuffle=True,\n",
    "    multi_horizon=True,\n",
    "):\n",
    "    \"\"\"Creates tensorflow dataset from numpy array.\n",
    "\n",
    "    This function creates a dataset where each element is a tuple `(inputs, targets)`.\n",
    "    `inputs` is a Tensor\n",
    "    of shape `(batch_size, input_sequence_length, num_routes, 1)` containing\n",
    "    the `input_sequence_length` past values of the timeseries for each node.\n",
    "    `targets` is a Tensor of shape `(batch_size, forecast_horizon, num_routes)`\n",
    "    containing the `forecast_horizon`\n",
    "    future values of the timeseries for each node.\n",
    "\n",
    "    Args:\n",
    "        data_array: np.ndarray with shape `(num_time_steps, num_routes)`\n",
    "        input_sequence_length: Length of the input sequence (in number of timesteps).\n",
    "        forecast_horizon: If `multi_horizon=True`, the target will be the values of the timeseries for 1 to\n",
    "            `forecast_horizon` timesteps ahead. If `multi_horizon=False`, the target will be the value of the\n",
    "            timeseries `forecast_horizon` steps ahead (only one value).\n",
    "        batch_size: Number of timeseries samples in each batch.\n",
    "        shuffle: Whether to shuffle output samples, or instead draw them in chronological order.\n",
    "        multi_horizon: See `forecast_horizon`.\n",
    "\n",
    "    Returns:\n",
    "        A tf.data.Dataset instance.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = timeseries_dataset_from_array(\n",
    "        # np.expand_dims(data_array[:-forecast_horizon], axis=-1),\n",
    "        data_array[:-forecast_horizon],\n",
    "        None,\n",
    "        sequence_length=input_sequence_length,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "\n",
    "    dataset = inputs\n",
    "    target_offset = (\n",
    "       input_sequence_length\n",
    "       if multi_horizon\n",
    "       else input_sequence_length + forecast_horizon - 1) \n",
    "    target_seq_length = forecast_horizon if multi_horizon else 1\n",
    "    targets = timeseries_dataset_from_array(\n",
    "        target_array[target_offset:],\n",
    "        None,\n",
    "        sequence_length=target_seq_length,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,)\n",
    "    \n",
    "\n",
    "    dataset = tf.data.Dataset.zip((inputs, targets))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(100)\n",
    "\n",
    "    return dataset.prefetch(16).cache()\n",
    "\n",
    "\n",
    "# train_dataset, val_dataset = (\n",
    " #    create_tf_dataset(data_array, input_sequence_length, forecast_horizon, batch_size)\n",
    " #    for data_array in [train_array, val_arrayylist]) \n",
    "\n",
    "# test_dataset = create_tf_dataset(\n",
    "#     Xarray, Yarray,  input_sequence_length,\n",
    "#     forecast_horizon,\n",
    "#     batch_size=test_array.shape[0],\n",
    "#     shuffle=False,\n",
    "#     multi_horizon=multi_horizon,\n",
    "# )\n",
    "\n",
    "test_dataset = create_tf_dataset(\n",
    "    Xarray, Yarray,  input_sequence_length,\n",
    "    forecast_horizon,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    multi_horizon=multi_horizon,\n",
    ")\n",
    "\n",
    "\n",
    "print(test_dataset)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "class GraphInfo:\n",
    "    def __init__(self, edges: typing.Tuple[list, list], num_nodes: int):\n",
    "        self.edges = edges\n",
    "        self.num_nodes = num_nodes\n",
    "\n",
    "adjacency_matrix = distance_weight_adjacency(airports, threshold=100000) # getAdjacencyMatrix(airports)[10]\n",
    "print(adjacency_matrix.shape)\n",
    "node_indices, neighbor_indices = np.where(adjacency_matrix != 0)\n",
    "graph = GraphInfo(\n",
    "    edges=(node_indices.tolist(), neighbor_indices.tolist()),\n",
    "    num_nodes=adjacency_matrix.shape[0],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(adjacency_matrix)\n",
    "plt.xticks(range(len(airports)), airports, fontsize=12, rotation=-90)\n",
    "plt.yticks(range(len(airports)), airports, fontsize=12, rotation=0)\n",
    "plt.show()\n",
    "# print(len(graph.edges[0]))\n",
    "# print(graph.edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GraphConv(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_feat,\n",
    "        out_feat,\n",
    "        graph_info: GraphInfo,\n",
    "        aggregation_type=\"mean\",\n",
    "        combination_type=\"concat\",\n",
    "        activation: typing.Optional[str] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.in_feat = in_feat\n",
    "        self.out_feat = out_feat\n",
    "        self.graph_info = graph_info\n",
    "        self.aggregation_type = aggregation_type\n",
    "        self.combination_type = combination_type\n",
    "        self.weight = tf.Variable(\n",
    "            initial_value=keras.initializers.glorot_uniform()(\n",
    "                shape=(in_feat, out_feat), dtype=\"float32\"\n",
    "            ),\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.activation = layers.Activation(activation)\n",
    "\n",
    "    def aggregate(self, neighbour_representations: tf.Tensor):\n",
    "        aggregation_func = {\n",
    "            \"sum\": tf.math.unsorted_segment_sum,\n",
    "            \"mean\": tf.math.unsorted_segment_mean,\n",
    "            \"max\": tf.math.unsorted_segment_max,\n",
    "        }.get(self.aggregation_type)\n",
    "\n",
    "        if aggregation_func:\n",
    "            return aggregation_func(\n",
    "                neighbour_representations,\n",
    "                self.graph_info.edges[0],\n",
    "                num_segments=self.graph_info.num_nodes,\n",
    "            )\n",
    "\n",
    "        raise ValueError(f\"Invalid aggregation type: {self.aggregation_type}\")\n",
    "\n",
    "    def compute_nodes_representation(self, features: tf.Tensor):\n",
    "        \"\"\"Computes each node's representation.\n",
    "\n",
    "        The nodes' representations are obtained by multiplying the features tensor with\n",
    "        `self.weight`. Note that\n",
    "        `self.weight` has shape `(in_feat, out_feat)`.\n",
    "\n",
    "        Args:\n",
    "            features: Tensor of shape `(num_nodes, batch_size, input_seq_len, in_feat)`\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape `(num_nodes, batch_size, input_seq_len, out_feat)`\n",
    "        \"\"\"\n",
    "        return tf.matmul(features, self.weight)\n",
    "\n",
    "    def compute_aggregated_messages(self, features: tf.Tensor):\n",
    "        neighbour_representations = tf.gather(features, self.graph_info.edges[1])\n",
    "        aggregated_messages = self.aggregate(neighbour_representations)\n",
    "        return tf.matmul(aggregated_messages, self.weight)\n",
    "\n",
    "    def update(self, nodes_representation: tf.Tensor, aggregated_messages: tf.Tensor):\n",
    "        if self.combination_type == \"concat\":\n",
    "            h = tf.concat([nodes_representation, aggregated_messages], axis=-1)\n",
    "        elif self.combination_type == \"add\":\n",
    "            h = nodes_representation + aggregated_messages\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid combination type: {self.combination_type}.\")\n",
    "\n",
    "        return self.activation(h)\n",
    "\n",
    "    def call(self, features: tf.Tensor):\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Args:\n",
    "            features: tensor of shape `(num_nodes, batch_size, input_seq_len, in_feat)`\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape `(num_nodes, batch_size, input_seq_len, out_feat)`\n",
    "        \"\"\"\n",
    "        nodes_representation = self.compute_nodes_representation(features)\n",
    "        aggregated_messages = self.compute_aggregated_messages(features)\n",
    "        return self.update(nodes_representation, aggregated_messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM including graph convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMGC(layers.Layer):\n",
    "    \"\"\"Layer comprising a convolution layer followed by LSTM and dense layers.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_feat,\n",
    "        out_feat,\n",
    "        lstm_units: int,\n",
    "        input_seq_len: int,\n",
    "        output_seq_len: int,\n",
    "        graph_info: GraphInfo,\n",
    "        graph_conv_params: typing.Optional[dict] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # graph conv layer\n",
    "        if graph_conv_params is None:\n",
    "            graph_conv_params = {\n",
    "                \"aggregation_type\": \"mean\",\n",
    "                \"combination_type\": \"concat\",\n",
    "                \"activation\": None,\n",
    "            }\n",
    "        self.graph_conv = GraphConv(in_feat, out_feat, graph_info, **graph_conv_params)\n",
    "\n",
    "        self.lstm = layers.LSTM(lstm_units, activation=\"relu\")\n",
    "        self.denseinpu = layers.Dense(output_seq_len)\n",
    "\n",
    "        self.input_seq_len, self.output_seq_len = input_seq_len, output_seq_len\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Args:\n",
    "            inputs: tf.Tensor of shape `(batch_size, input_seq_len, num_nodes, in_feat)`\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape `(batch_size, output_seq_len, num_nodes)`.\n",
    "        \"\"\"\n",
    "\n",
    "        # convert shape to  (num_nodes, batch_size, input_seq_len, in_feat)\n",
    "        inputs = tf.transpose(inputs, [2, 0, 1, 3])\n",
    "\n",
    "        gcn_out = self.graph_conv(\n",
    "            inputs\n",
    "        )  # gcn_out has shape: (num_nodes, batch_size, input_seq_len, out_feat)\n",
    "        shape = tf.shape(gcn_out)\n",
    "        num_nodes, batch_size, input_seq_len, out_feat = (\n",
    "            shape[0],\n",
    "            shape[1],\n",
    "            shape[2],\n",
    "            shape[3],\n",
    "        )\n",
    "\n",
    "        # LSTM takes only 3D tensors as input\n",
    "        gcn_out = tf.reshape(gcn_out, (batch_size * num_nodes, input_seq_len, out_feat))\n",
    "        print(f\"The GCN output shape  = {gcn_out}\")\n",
    "        lstm_out = self.lstm(gcn_out)  # lstm_out has shape: (batch_size * num_nodes, lstm_units)\n",
    "        print(f\"The LSTM output shape  = {lstm_out}\")\n",
    "        dense_output = self.dense(\n",
    "            lstm_out\n",
    "        )\n",
    "        print(f\"The Dense has output shape {dense_output}\")  # dense_output has shape: (batch_size * num_nodes, output_seq_len)\n",
    "        output = tf.reshape(dense_output, (num_nodes, batch_size, self.output_seq_len))\n",
    "        return #dense_output\n",
    "        tf.transpose(\n",
    "            output, [1, 2, 0])  \n",
    "        # # returns Tensor of shape (batch_size, output_seq_len, num_nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GCN output shape  = Tensor(\"lstmgc_9/Reshape:0\", shape=(None, 12, 20), dtype=float32)\n",
      "The LSTM output shape  = Tensor(\"lstmgc_9/lstm_9/strided_slice_3:0\", shape=(None, 64), dtype=float32)\n",
      "The Dense has output shape Tensor(\"lstmgc_9/dense_9/BiasAdd:0\", shape=(None, 3), dtype=float32)\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 12, 10, 9)]       0         \n",
      "                                                                 \n",
      " lstmgc_9 (LSTMGC)           multiple                  22045     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,045\n",
      "Trainable params: 22,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "The GCN output shape  = Tensor(\"model_7/lstmgc_9/Reshape:0\", shape=(None, 12, 20), dtype=float32)\n",
      "The LSTM output shape  = Tensor(\"model_7/lstmgc_9/lstm_9/strided_slice_3:0\", shape=(None, 64), dtype=float32)\n",
      "The Dense has output shape Tensor(\"model_7/lstmgc_9/dense_9/BiasAdd:0\", shape=(None, 3), dtype=float32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\bcsli\\Documents\\TU Delft\\Third Year\\Project\\spektral-environment\\with_spektral\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\bcsli\\Documents\\TU Delft\\Third Year\\Project\\spektral-environment\\with_spektral\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\bcsli\\Documents\\TU Delft\\Third Year\\Project\\spektral-environment\\with_spektral\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\bcsli\\Documents\\TU Delft\\Third Year\\Project\\spektral-environment\\with_spektral\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"c:\\Users\\bcsli\\Documents\\TU Delft\\Third Year\\Project\\spektral-environment\\with_spektral\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 199, in __call__\n        y_t, y_p, sw = match_dtype_and_rank(y_t, y_p, sw)\n    File \"c:\\Users\\bcsli\\Documents\\TU Delft\\Third Year\\Project\\spektral-environment\\with_spektral\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 685, in match_dtype_and_rank\n        if ((y_t.dtype.is_floating and y_p.dtype.is_floating) or\n\n    AttributeError: 'NoneType' object has no attribute 'dtype'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1720/4269968399.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     33\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m model.fit(\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mtest_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bcsli\\Documents\\TU Delft\\Third Year\\Project\\spektral-environment\\with_spektral\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bcsli\\Documents\\TU Delft\\Third Year\\Project\\spektral-environment\\with_spektral\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"c:\\Users\\bcsli\\Documents\\TU Delft\\Third Year\\Project\\spektral-environment\\with_spektral\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\bcsli\\Documents\\TU Delft\\Third Year\\Project\\spektral-environment\\with_spektral\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\bcsli\\Documents\\TU Delft\\Third Year\\Project\\spektral-environment\\with_spektral\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\bcsli\\Documents\\TU Delft\\Third Year\\Project\\spektral-environment\\with_spektral\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"c:\\Users\\bcsli\\Documents\\TU Delft\\Third Year\\Project\\spektral-environment\\with_spektral\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 199, in __call__\n        y_t, y_p, sw = match_dtype_and_rank(y_t, y_p, sw)\n    File \"c:\\Users\\bcsli\\Documents\\TU Delft\\Third Year\\Project\\spektral-environment\\with_spektral\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 685, in match_dtype_and_rank\n        if ((y_t.dtype.is_floating and y_p.dtype.is_floating) or\n\n    AttributeError: 'NoneType' object has no attribute 'dtype'\n"
     ]
    }
   ],
   "source": [
    "in_feat = 9\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "input_sequence_length = 12\n",
    "forecast_horizon = 3\n",
    "multi_horizon = False\n",
    "out_feat = 10\n",
    "lstm_units = 64\n",
    "graph_conv_params = {\n",
    "    \"aggregation_type\": \"mean\",\n",
    "    \"combination_type\": \"concat\",\n",
    "    \"activation\": None,\n",
    "}\n",
    "\n",
    "st_gcn = LSTMGC(\n",
    "    in_feat,\n",
    "    out_feat,\n",
    "    lstm_units,\n",
    "    input_sequence_length,\n",
    "    forecast_horizon,\n",
    "    graph,\n",
    "    graph_conv_params,\n",
    ")\n",
    "inputs = layers.Input((input_sequence_length, graph.num_nodes, in_feat))\n",
    "outputs = st_gcn(inputs)\n",
    "\n",
    "model = keras.models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=0.0002),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    ")\n",
    "model.summary()\n",
    "model.fit(\n",
    "    test_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a8b8190b409df59d083e48feca7ac41a34361ff0d7727e2b40e3d45f8724b63"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
